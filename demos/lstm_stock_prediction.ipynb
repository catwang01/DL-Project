{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[toc]\n",
    "\n",
    "# Tensorflow2 利用 lstm 实现股票预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T06:46:47.227573Z",
     "start_time": "2020-07-28T06:46:42.503337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本接口即将停止更新，请尽快使用Pro版接口：https://tushare.pro/document/2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tushare as ts\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "seq_length = 20\n",
    "input_dim = 5\n",
    "output_dim = 1\n",
    "\n",
    "stock_data = ts.get_k_data('600000', start='2016-01-01', end='2018-11-20')\n",
    "features = ['open', 'high', 'low', 'volume', 'close']\n",
    "target = ['close']\n",
    "data = stock_data[features].values # shape = (685, 5)\n",
    "target = stock_data[target].values # shape = (685, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分验证集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里不用 sklearn.model_selection.train_test_split，因为这会导致数据穿越"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T06:46:47.238761Z",
     "start_time": "2020-07-28T06:46:47.231329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 616, val sizse: 69\n"
     ]
    }
   ],
   "source": [
    "val_rate = 0.1\n",
    "sample_size = data.shape[0]\n",
    "train_size = int(sample_size * (1 - val_rate))\n",
    "x_train, x_val, y_train, y_val = data[:train_size], data[train_size:], target[:train_size], target[:train_size]\n",
    "\n",
    "print(f\"train size: {train_size}, val sizse: {sample_size - train_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对数据进行标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T06:46:47.244674Z",
     "start_time": "2020-07-28T06:46:47.240750Z"
    }
   },
   "outputs": [],
   "source": [
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "x_train_scaled = x_scaler.fit_transform(x_train)\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "x_val_scaled = x_scaler.transform(x_val)\n",
    "y_val_scaled = y_scaler.transform(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得序列数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T06:46:47.252455Z",
     "start_time": "2020-07-28T06:46:47.246917Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sequence_data(x, y):\n",
    "    n = x.shape[0]\n",
    "    sample_size = n - (seq_length + 1)\n",
    "    x_sequence_sample = np.array([x[i:i+seq_length] for i in range(sample_size)])\n",
    "    y_sequence_sample = np.array([y[i+seq_length] for i in range(sample_size)])\n",
    "    return x_sequence_sample, y_sequence_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T06:46:47.264009Z",
     "start_time": "2020-07-28T06:46:47.258187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_sequence shape: (595, 20, 5), y_train_sequence shape: (595, 1)\n",
      "x_val_sequence shape: (48, 20, 5), y_val_sequence shape: (48, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_sequence, y_train_sequence = get_sequence_data(x_train_scaled, y_train_scaled)\n",
    "x_val_sequence, y_val_sequence = get_sequence_data(x_val_scaled, y_val_scaled)\n",
    "\n",
    "print(f\"x_train_sequence shape: {x_train_sequence.shape}, y_train_sequence shape: {y_train_sequence.shape}\")\n",
    "print(f\"x_val_sequence shape: {x_val_sequence.shape}, y_val_sequence shape: {y_val_sequence.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T06:48:10.964210Z",
     "start_time": "2020-07-28T06:46:59.753827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 595 samples, validate on 48 samples\n",
      "Epoch 1/1000\n",
      "595/595 [==============================] - 2s 3ms/sample - loss: 3656.6171 - val_loss: 0.6933\n",
      "Epoch 2/1000\n",
      "595/595 [==============================] - 0s 464us/sample - loss: 547.4767 - val_loss: 0.7901\n",
      "Epoch 3/1000\n",
      "595/595 [==============================] - 0s 355us/sample - loss: 172.6736 - val_loss: 0.9487\n",
      "Epoch 4/1000\n",
      "595/595 [==============================] - 0s 354us/sample - loss: 5.0123 - val_loss: 1.0047\n",
      "Epoch 5/1000\n",
      "595/595 [==============================] - 0s 392us/sample - loss: 42.2900 - val_loss: 0.7668\n",
      "Epoch 6/1000\n",
      "595/595 [==============================] - 0s 350us/sample - loss: 1852.0115 - val_loss: 0.9010\n",
      "Epoch 7/1000\n",
      "595/595 [==============================] - 0s 356us/sample - loss: 68.3455 - val_loss: 0.8221\n",
      "Epoch 8/1000\n",
      "595/595 [==============================] - 0s 341us/sample - loss: 732.2887 - val_loss: 0.8849\n",
      "Epoch 9/1000\n",
      "595/595 [==============================] - 0s 357us/sample - loss: 68.2523 - val_loss: 0.8807\n",
      "Epoch 10/1000\n",
      "595/595 [==============================] - 0s 389us/sample - loss: 531.7745 - val_loss: 0.8904\n",
      "Epoch 11/1000\n",
      "595/595 [==============================] - 0s 446us/sample - loss: 42.8643 - val_loss: 0.8730\n",
      "Epoch 12/1000\n",
      "595/595 [==============================] - 0s 378us/sample - loss: 963.6859 - val_loss: 0.8964\n",
      "Epoch 13/1000\n",
      "595/595 [==============================] - 0s 391us/sample - loss: 46.7880 - val_loss: 0.8856\n",
      "Epoch 14/1000\n",
      "595/595 [==============================] - 0s 426us/sample - loss: 194.2924 - val_loss: 0.7998\n",
      "Epoch 15/1000\n",
      "595/595 [==============================] - 0s 372us/sample - loss: 86.5446 - val_loss: 0.9055\n",
      "Epoch 16/1000\n",
      "595/595 [==============================] - 0s 393us/sample - loss: 229.9487 - val_loss: 0.9005\n",
      "Epoch 17/1000\n",
      "595/595 [==============================] - 0s 419us/sample - loss: 7.8343 - val_loss: 0.9005\n",
      "Epoch 18/1000\n",
      "595/595 [==============================] - 0s 402us/sample - loss: 222.7581 - val_loss: 0.9037\n",
      "Epoch 19/1000\n",
      "595/595 [==============================] - 0s 430us/sample - loss: 93.2919 - val_loss: 0.8720\n",
      "Epoch 20/1000\n",
      "595/595 [==============================] - 0s 367us/sample - loss: 153.6514 - val_loss: 0.8636\n",
      "Epoch 21/1000\n",
      "595/595 [==============================] - 0s 424us/sample - loss: 22.1374 - val_loss: 0.9001\n",
      "Epoch 22/1000\n",
      "595/595 [==============================] - 0s 441us/sample - loss: 228.6745 - val_loss: 0.9001\n",
      "Epoch 23/1000\n",
      "595/595 [==============================] - 0s 407us/sample - loss: 144.3487 - val_loss: 0.8962\n",
      "Epoch 24/1000\n",
      "595/595 [==============================] - 0s 434us/sample - loss: 115.9598 - val_loss: 0.8828\n",
      "Epoch 25/1000\n",
      "595/595 [==============================] - 0s 588us/sample - loss: 154.1259 - val_loss: 0.8860\n",
      "Epoch 26/1000\n",
      "595/595 [==============================] - 0s 401us/sample - loss: 33.2085 - val_loss: 0.8795\n",
      "Epoch 27/1000\n",
      "595/595 [==============================] - 0s 447us/sample - loss: 35.9920 - val_loss: 0.8707\n",
      "Epoch 28/1000\n",
      "595/595 [==============================] - 0s 476us/sample - loss: 53.9995 - val_loss: 0.8577\n",
      "Epoch 29/1000\n",
      "595/595 [==============================] - 0s 425us/sample - loss: 39.9361 - val_loss: 0.8447\n",
      "Epoch 30/1000\n",
      "595/595 [==============================] - 0s 485us/sample - loss: 49.4288 - val_loss: 0.8338\n",
      "Epoch 31/1000\n",
      "595/595 [==============================] - 0s 434us/sample - loss: 21.1499 - val_loss: 0.8202\n",
      "Epoch 32/1000\n",
      "595/595 [==============================] - 0s 408us/sample - loss: 46.3349 - val_loss: 0.8042\n",
      "Epoch 33/1000\n",
      "595/595 [==============================] - 0s 473us/sample - loss: 28.5800 - val_loss: 0.7816\n",
      "Epoch 34/1000\n",
      "595/595 [==============================] - 0s 412us/sample - loss: 35.5096 - val_loss: 0.7617\n",
      "Epoch 35/1000\n",
      "595/595 [==============================] - 0s 427us/sample - loss: 28.3928 - val_loss: 0.7336\n",
      "Epoch 36/1000\n",
      "595/595 [==============================] - 0s 493us/sample - loss: 57.9904 - val_loss: 0.7059\n",
      "Epoch 37/1000\n",
      "595/595 [==============================] - 0s 429us/sample - loss: 16.4851 - val_loss: 0.6786\n",
      "Epoch 38/1000\n",
      "595/595 [==============================] - 0s 433us/sample - loss: 64.8000 - val_loss: 0.6572\n",
      "Epoch 39/1000\n",
      "595/595 [==============================] - 0s 434us/sample - loss: 17.2038 - val_loss: 0.6349\n",
      "Epoch 40/1000\n",
      "595/595 [==============================] - 0s 473us/sample - loss: 129.1241 - val_loss: 0.6165\n",
      "Epoch 41/1000\n",
      "595/595 [==============================] - 0s 419us/sample - loss: 38.2539 - val_loss: 0.6018\n",
      "Epoch 42/1000\n",
      "595/595 [==============================] - 0s 534us/sample - loss: 18.7604 - val_loss: 0.5859\n",
      "Epoch 43/1000\n",
      "595/595 [==============================] - 0s 413us/sample - loss: 28.2586 - val_loss: 0.8281\n",
      "Epoch 44/1000\n",
      "595/595 [==============================] - 0s 459us/sample - loss: 8.4356 - val_loss: 0.8224\n",
      "Epoch 45/1000\n",
      "595/595 [==============================] - 0s 400us/sample - loss: 147.8492 - val_loss: 0.7864\n",
      "Epoch 46/1000\n",
      "595/595 [==============================] - 0s 483us/sample - loss: 66.2814 - val_loss: 0.7488\n",
      "Epoch 47/1000\n",
      "595/595 [==============================] - 0s 432us/sample - loss: 51.9259 - val_loss: 0.7026\n",
      "Epoch 48/1000\n",
      "595/595 [==============================] - 0s 397us/sample - loss: 17.3071 - val_loss: 0.6670\n",
      "Epoch 49/1000\n",
      "595/595 [==============================] - 0s 425us/sample - loss: 35.7026 - val_loss: 0.6338\n",
      "Epoch 50/1000\n",
      "595/595 [==============================] - 0s 417us/sample - loss: 61.2586 - val_loss: 0.6118\n",
      "Epoch 51/1000\n",
      "595/595 [==============================] - 0s 404us/sample - loss: 26.5289 - val_loss: 0.5885\n",
      "Epoch 52/1000\n",
      "595/595 [==============================] - 0s 404us/sample - loss: 63.9140 - val_loss: 0.5735\n",
      "Epoch 53/1000\n",
      "595/595 [==============================] - 0s 496us/sample - loss: 0.5738 - val_loss: 0.5582\n",
      "Epoch 54/1000\n",
      "595/595 [==============================] - 0s 473us/sample - loss: 56.9346 - val_loss: 0.5514\n",
      "Epoch 55/1000\n",
      "595/595 [==============================] - 0s 394us/sample - loss: 15.2474 - val_loss: 0.5382\n",
      "Epoch 56/1000\n",
      "595/595 [==============================] - 0s 397us/sample - loss: 69.6078 - val_loss: 0.5335\n",
      "Epoch 57/1000\n",
      "595/595 [==============================] - 0s 446us/sample - loss: 7.2468 - val_loss: 0.5280\n",
      "Epoch 58/1000\n",
      "595/595 [==============================] - 0s 441us/sample - loss: 72.2152 - val_loss: 0.5240\n",
      "Epoch 59/1000\n",
      "595/595 [==============================] - 0s 431us/sample - loss: 2.4624 - val_loss: 0.5249\n",
      "Epoch 60/1000\n",
      "595/595 [==============================] - 0s 438us/sample - loss: 53.9822 - val_loss: 0.5242\n",
      "Epoch 61/1000\n",
      "595/595 [==============================] - 0s 515us/sample - loss: 1.0183 - val_loss: 0.5209\n",
      "Epoch 62/1000\n",
      "595/595 [==============================] - 0s 507us/sample - loss: 98.0907 - val_loss: 0.5158\n",
      "Epoch 63/1000\n",
      "595/595 [==============================] - 0s 440us/sample - loss: 20.1080 - val_loss: 0.5102\n",
      "Epoch 64/1000\n",
      "595/595 [==============================] - 0s 452us/sample - loss: 60.3025 - val_loss: 0.5087\n",
      "Epoch 65/1000\n",
      "595/595 [==============================] - 0s 519us/sample - loss: 12.6971 - val_loss: 0.5089\n",
      "Epoch 66/1000\n",
      "595/595 [==============================] - 0s 527us/sample - loss: 117.4295 - val_loss: 0.9806\n",
      "Epoch 67/1000\n",
      "595/595 [==============================] - 0s 535us/sample - loss: 126.2094 - val_loss: 0.9778\n",
      "Epoch 68/1000\n",
      "595/595 [==============================] - 0s 584us/sample - loss: 83.2224 - val_loss: 0.9324\n",
      "Epoch 69/1000\n",
      "595/595 [==============================] - 0s 462us/sample - loss: 14.9517 - val_loss: 0.9209\n",
      "Epoch 70/1000\n",
      "595/595 [==============================] - 0s 417us/sample - loss: 57.8723 - val_loss: 0.9105\n",
      "Epoch 71/1000\n",
      "595/595 [==============================] - 0s 394us/sample - loss: 4.1149 - val_loss: 0.9060\n",
      "Epoch 72/1000\n",
      "595/595 [==============================] - 0s 390us/sample - loss: 90.3760 - val_loss: 0.8964\n",
      "Epoch 73/1000\n",
      "595/595 [==============================] - 0s 391us/sample - loss: 19.8949 - val_loss: 0.8828\n",
      "Epoch 74/1000\n",
      "595/595 [==============================] - 0s 390us/sample - loss: 98.9286 - val_loss: 0.8724\n",
      "Epoch 75/1000\n",
      "595/595 [==============================] - 0s 393us/sample - loss: 27.6997 - val_loss: 0.8612\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595/595 [==============================] - 0s 374us/sample - loss: 48.9200 - val_loss: 0.8697\n",
      "Epoch 77/1000\n",
      "595/595 [==============================] - 0s 383us/sample - loss: 15.9667 - val_loss: 0.8698\n",
      "Epoch 78/1000\n",
      "595/595 [==============================] - 0s 388us/sample - loss: 50.5188 - val_loss: 0.8679\n",
      "Epoch 79/1000\n",
      "595/595 [==============================] - 0s 404us/sample - loss: 9.3886 - val_loss: 0.8619\n",
      "Epoch 80/1000\n",
      "595/595 [==============================] - 0s 394us/sample - loss: 50.8406 - val_loss: 0.8575\n",
      "Epoch 81/1000\n",
      "595/595 [==============================] - 0s 371us/sample - loss: 13.9384 - val_loss: 0.8509\n",
      "Epoch 82/1000\n",
      "595/595 [==============================] - 0s 366us/sample - loss: 54.8967 - val_loss: 0.8436\n",
      "Epoch 83/1000\n",
      "595/595 [==============================] - 0s 376us/sample - loss: 6.0691 - val_loss: 0.8372\n",
      "Epoch 84/1000\n",
      "595/595 [==============================] - 0s 428us/sample - loss: 55.1786 - val_loss: 0.8311\n",
      "Epoch 85/1000\n",
      "595/595 [==============================] - 0s 399us/sample - loss: 9.5706 - val_loss: 0.8211\n",
      "Epoch 86/1000\n",
      "595/595 [==============================] - 0s 365us/sample - loss: 52.9001 - val_loss: 0.8133\n",
      "Epoch 87/1000\n",
      "595/595 [==============================] - 0s 371us/sample - loss: 14.8353 - val_loss: 0.8050\n",
      "Epoch 88/1000\n",
      "595/595 [==============================] - 0s 401us/sample - loss: 46.1429 - val_loss: 0.7946\n",
      "Epoch 89/1000\n",
      "595/595 [==============================] - 0s 410us/sample - loss: 15.3096 - val_loss: 0.7896\n",
      "Epoch 90/1000\n",
      "595/595 [==============================] - 0s 398us/sample - loss: 86.4660 - val_loss: 0.7770\n",
      "Epoch 91/1000\n",
      "595/595 [==============================] - 0s 470us/sample - loss: 37.3023 - val_loss: 0.7635\n",
      "Epoch 92/1000\n",
      "595/595 [==============================] - 0s 416us/sample - loss: 40.4541 - val_loss: 0.7526\n",
      "Epoch 93/1000\n",
      "595/595 [==============================] - 0s 453us/sample - loss: 27.8893 - val_loss: 0.7408\n",
      "Epoch 94/1000\n",
      "595/595 [==============================] - 0s 503us/sample - loss: 39.3546 - val_loss: 0.7300\n",
      "Epoch 95/1000\n",
      "595/595 [==============================] - 0s 430us/sample - loss: 16.8470 - val_loss: 0.7194\n",
      "Epoch 96/1000\n",
      "595/595 [==============================] - 0s 481us/sample - loss: 39.8155 - val_loss: 0.7085\n",
      "Epoch 97/1000\n",
      "595/595 [==============================] - 0s 704us/sample - loss: 9.9852 - val_loss: 0.7001\n",
      "Epoch 98/1000\n",
      "595/595 [==============================] - 0s 564us/sample - loss: 106.0145 - val_loss: 0.6904\n",
      "Epoch 99/1000\n",
      "595/595 [==============================] - 0s 462us/sample - loss: 55.4098 - val_loss: 0.6793\n",
      "Epoch 100/1000\n",
      "595/595 [==============================] - 0s 554us/sample - loss: 33.4010 - val_loss: 0.6693\n",
      "Epoch 101/1000\n",
      "595/595 [==============================] - 0s 460us/sample - loss: 12.2429 - val_loss: 0.6531\n",
      "Epoch 102/1000\n",
      "595/595 [==============================] - 0s 441us/sample - loss: 33.4889 - val_loss: 0.6431\n",
      "Epoch 103/1000\n",
      "595/595 [==============================] - 0s 503us/sample - loss: 31.8337 - val_loss: 0.6347\n",
      "Epoch 104/1000\n",
      "595/595 [==============================] - 0s 455us/sample - loss: 59.2235 - val_loss: 0.6195\n",
      "Epoch 105/1000\n",
      "595/595 [==============================] - 0s 474us/sample - loss: 19.0030 - val_loss: 0.6125\n",
      "Epoch 106/1000\n",
      "595/595 [==============================] - 0s 414us/sample - loss: 43.0933 - val_loss: 0.6024\n",
      "Epoch 107/1000\n",
      "595/595 [==============================] - 0s 428us/sample - loss: 5.8054 - val_loss: 0.5996\n",
      "Epoch 108/1000\n",
      "595/595 [==============================] - 0s 509us/sample - loss: 51.9886 - val_loss: 0.5930\n",
      "Epoch 109/1000\n",
      "595/595 [==============================] - 0s 401us/sample - loss: 18.1183 - val_loss: 0.5776\n",
      "Epoch 110/1000\n",
      "595/595 [==============================] - 0s 457us/sample - loss: 79.8759 - val_loss: 0.5751\n",
      "Epoch 111/1000\n",
      "595/595 [==============================] - 0s 445us/sample - loss: 25.3630 - val_loss: 0.5755\n",
      "Epoch 112/1000\n",
      "595/595 [==============================] - 0s 388us/sample - loss: 35.5249 - val_loss: 0.5677\n",
      "Epoch 113/1000\n",
      "595/595 [==============================] - 0s 375us/sample - loss: 9.0472 - val_loss: 0.5711\n",
      "Epoch 114/1000\n",
      "595/595 [==============================] - 0s 423us/sample - loss: 48.0541 - val_loss: 0.5603\n",
      "Epoch 115/1000\n",
      "595/595 [==============================] - 0s 377us/sample - loss: 8.5193 - val_loss: 0.5577\n",
      "Epoch 116/1000\n",
      "595/595 [==============================] - 0s 370us/sample - loss: 53.6942 - val_loss: 0.5513\n",
      "Epoch 117/1000\n",
      "595/595 [==============================] - 0s 377us/sample - loss: 5.8059 - val_loss: 0.5483\n",
      "Epoch 118/1000\n",
      "595/595 [==============================] - 0s 384us/sample - loss: 37.0379 - val_loss: 0.5424\n",
      "Epoch 119/1000\n",
      "595/595 [==============================] - 0s 406us/sample - loss: 7.9215 - val_loss: 0.5439\n",
      "Epoch 120/1000\n",
      "595/595 [==============================] - 0s 395us/sample - loss: 36.2554 - val_loss: 0.5353\n",
      "Epoch 121/1000\n",
      "595/595 [==============================] - 0s 390us/sample - loss: 8.2904 - val_loss: 0.5369\n",
      "Epoch 122/1000\n",
      "595/595 [==============================] - 0s 392us/sample - loss: 57.2618 - val_loss: 0.5324\n",
      "Epoch 123/1000\n",
      "595/595 [==============================] - 0s 396us/sample - loss: 14.4556 - val_loss: 0.5201\n",
      "Epoch 124/1000\n",
      "595/595 [==============================] - 0s 441us/sample - loss: 79.8851 - val_loss: 0.5188\n",
      "Epoch 125/1000\n",
      "595/595 [==============================] - 0s 381us/sample - loss: 33.7679 - val_loss: 0.5258\n",
      "Epoch 126/1000\n",
      "595/595 [==============================] - 0s 406us/sample - loss: 48.5126 - val_loss: 0.5187\n",
      "Epoch 127/1000\n",
      "595/595 [==============================] - 0s 387us/sample - loss: 7.3641 - val_loss: 0.5176\n",
      "Epoch 128/1000\n",
      "595/595 [==============================] - 0s 397us/sample - loss: 36.5719 - val_loss: 0.5121\n",
      "Epoch 129/1000\n",
      "595/595 [==============================] - 0s 395us/sample - loss: 10.0917 - val_loss: 0.5114\n",
      "Epoch 130/1000\n",
      "595/595 [==============================] - 0s 396us/sample - loss: 40.3638 - val_loss: 0.5053\n",
      "Epoch 131/1000\n",
      "595/595 [==============================] - 0s 385us/sample - loss: 10.7254 - val_loss: 0.5036\n",
      "Epoch 132/1000\n",
      "595/595 [==============================] - 0s 409us/sample - loss: 21.6457 - val_loss: 0.5060\n",
      "Epoch 133/1000\n",
      "595/595 [==============================] - 0s 433us/sample - loss: 34.8400 - val_loss: 0.4993\n",
      "Epoch 134/1000\n",
      "595/595 [==============================] - 0s 434us/sample - loss: 26.3783 - val_loss: 0.5017\n",
      "Epoch 135/1000\n",
      "595/595 [==============================] - 0s 382us/sample - loss: 32.9263 - val_loss: 0.4956\n",
      "Epoch 136/1000\n",
      "595/595 [==============================] - 0s 410us/sample - loss: 23.8094 - val_loss: 0.4957\n",
      "Epoch 137/1000\n",
      "595/595 [==============================] - 0s 387us/sample - loss: 17.7138 - val_loss: 0.4898\n",
      "Epoch 138/1000\n",
      "595/595 [==============================] - 0s 394us/sample - loss: 33.0111 - val_loss: 0.4898\n",
      "Epoch 139/1000\n",
      "595/595 [==============================] - 0s 398us/sample - loss: 28.4225 - val_loss: 0.4915\n",
      "Epoch 140/1000\n",
      "595/595 [==============================] - 0s 394us/sample - loss: 4.7881 - val_loss: 0.4940\n",
      "Epoch 141/1000\n",
      "595/595 [==============================] - 0s 423us/sample - loss: 32.1989 - val_loss: 0.4888\n",
      "Epoch 142/1000\n",
      "595/595 [==============================] - 0s 405us/sample - loss: 27.6468 - val_loss: 0.4900\n",
      "Epoch 143/1000\n",
      "595/595 [==============================] - 0s 439us/sample - loss: 16.6315 - val_loss: 0.4844\n",
      "Epoch 144/1000\n",
      "595/595 [==============================] - 0s 420us/sample - loss: 33.7354 - val_loss: 0.4849\n",
      "Epoch 145/1000\n",
      "595/595 [==============================] - 0s 414us/sample - loss: 0.6564 - val_loss: 0.4899\n",
      "Epoch 146/1000\n",
      "595/595 [==============================] - 0s 447us/sample - loss: 99.7447 - val_loss: 0.4834\n",
      "Epoch 147/1000\n",
      "595/595 [==============================] - 0s 416us/sample - loss: 48.4927 - val_loss: 0.4755\n",
      "Epoch 148/1000\n",
      "595/595 [==============================] - 0s 392us/sample - loss: 24.9270 - val_loss: 0.4760\n",
      "Epoch 149/1000\n",
      "595/595 [==============================] - 0s 419us/sample - loss: 26.5993 - val_loss: 0.4696\n",
      "Epoch 150/1000\n",
      "595/595 [==============================] - 0s 395us/sample - loss: 29.0097 - val_loss: 0.4732\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595/595 [==============================] - 0s 392us/sample - loss: 25.9973 - val_loss: 0.4696\n",
      "Epoch 152/1000\n",
      "595/595 [==============================] - 0s 466us/sample - loss: 26.8308 - val_loss: 0.4732\n",
      "Epoch 153/1000\n",
      "595/595 [==============================] - 0s 393us/sample - loss: 31.9241 - val_loss: 0.4729\n",
      "Epoch 154/1000\n",
      "595/595 [==============================] - 0s 422us/sample - loss: 21.4038 - val_loss: 0.4753\n",
      "Epoch 155/1000\n",
      "595/595 [==============================] - 0s 438us/sample - loss: 27.3173 - val_loss: 0.4683\n",
      "Epoch 156/1000\n",
      "595/595 [==============================] - 0s 383us/sample - loss: 30.2271 - val_loss: 0.4741\n",
      "Epoch 157/1000\n",
      "595/595 [==============================] - 0s 393us/sample - loss: 21.7210 - val_loss: 0.4750\n",
      "Epoch 158/1000\n",
      "595/595 [==============================] - 0s 379us/sample - loss: 32.1272 - val_loss: 0.4721\n",
      "Epoch 159/1000\n",
      "595/595 [==============================] - 0s 386us/sample - loss: 3.9143 - val_loss: 0.4825\n",
      "Epoch 160/1000\n",
      "595/595 [==============================] - 0s 396us/sample - loss: 106.1617 - val_loss: 0.4845\n",
      "Epoch 161/1000\n",
      "595/595 [==============================] - 0s 423us/sample - loss: 60.8161 - val_loss: 0.4754\n",
      "Epoch 162/1000\n",
      "595/595 [==============================] - 0s 420us/sample - loss: 19.6458 - val_loss: 0.4771\n",
      "Epoch 163/1000\n",
      "595/595 [==============================] - 0s 384us/sample - loss: 28.1831 - val_loss: 0.4742\n",
      "Epoch 164/1000\n",
      "595/595 [==============================] - 0s 407us/sample - loss: 23.8360 - val_loss: 0.4791\n",
      "Epoch 165/1000\n",
      "595/595 [==============================] - 0s 406us/sample - loss: 32.7470 - val_loss: 0.4804\n",
      "Epoch 166/1000\n",
      "595/595 [==============================] - 0s 379us/sample - loss: 29.1642 - val_loss: 0.4843\n",
      "Epoch 167/1000\n",
      "595/595 [==============================] - 0s 419us/sample - loss: 18.1391 - val_loss: 0.4813\n",
      "Epoch 168/1000\n",
      "595/595 [==============================] - 0s 386us/sample - loss: 31.5184 - val_loss: 0.4831\n",
      "Epoch 169/1000\n",
      "595/595 [==============================] - 0s 395us/sample - loss: 31.3389 - val_loss: 0.4791\n",
      "Epoch 170/1000\n",
      "595/595 [==============================] - 0s 391us/sample - loss: 7.0723 - val_loss: 0.4792\n",
      "Epoch 171/1000\n",
      "595/595 [==============================] - 0s 524us/sample - loss: 27.6468 - val_loss: 0.4739\n",
      "Epoch 172/1000\n",
      "595/595 [==============================] - 0s 510us/sample - loss: 33.9667 - val_loss: 0.4729\n",
      "Epoch 173/1000\n",
      "595/595 [==============================] - 0s 532us/sample - loss: 25.2480 - val_loss: 0.4739\n",
      "Epoch 174/1000\n",
      "595/595 [==============================] - 0s 585us/sample - loss: 9.5577 - val_loss: 0.4782\n",
      "Epoch 175/1000\n",
      "595/595 [==============================] - 0s 527us/sample - loss: 30.6087 - val_loss: 0.4720\n",
      "Epoch 176/1000\n",
      "595/595 [==============================] - 0s 439us/sample - loss: 33.5727 - val_loss: 0.4733\n",
      "Epoch 177/1000\n",
      "595/595 [==============================] - 0s 432us/sample - loss: 9.3872 - val_loss: 0.4829\n",
      "Epoch 178/1000\n",
      "595/595 [==============================] - 0s 480us/sample - loss: 102.1024 - val_loss: 0.4817\n",
      "Epoch 179/1000\n",
      "595/595 [==============================] - 0s 446us/sample - loss: 40.8438 - val_loss: 0.4768\n",
      "Epoch 180/1000\n",
      "595/595 [==============================] - 0s 441us/sample - loss: 3.1787 - val_loss: 0.4744\n",
      "Epoch 181/1000\n",
      "595/595 [==============================] - 0s 430us/sample - loss: 28.3453 - val_loss: 0.4712\n",
      "Epoch 182/1000\n",
      "595/595 [==============================] - 0s 432us/sample - loss: 27.3526 - val_loss: 0.4744\n",
      "Epoch 183/1000\n",
      "595/595 [==============================] - 0s 443us/sample - loss: 27.8636 - val_loss: 0.4702\n",
      "Epoch 184/1000\n",
      "595/595 [==============================] - 0s 474us/sample - loss: 33.0733 - val_loss: 0.4721\n",
      "Epoch 185/1000\n",
      "595/595 [==============================] - 0s 440us/sample - loss: 29.1631 - val_loss: 0.4744\n",
      "Epoch 186/1000\n",
      "595/595 [==============================] - 0s 501us/sample - loss: 1.5516 - val_loss: 0.4790\n",
      "Epoch 187/1000\n",
      "595/595 [==============================] - 0s 514us/sample - loss: 35.4541 - val_loss: 0.4744\n",
      "Epoch 188/1000\n",
      "595/595 [==============================] - 0s 410us/sample - loss: 28.5538 - val_loss: 0.4704\n",
      "Epoch 189/1000\n",
      "595/595 [==============================] - 0s 439us/sample - loss: 8.6812 - val_loss: 0.4732\n",
      "Epoch 190/1000\n",
      "595/595 [==============================] - 0s 400us/sample - loss: 33.0347 - val_loss: 0.4748\n",
      "Epoch 191/1000\n",
      "595/595 [==============================] - 0s 407us/sample - loss: 22.3667 - val_loss: 0.4738\n",
      "Epoch 192/1000\n",
      "595/595 [==============================] - 0s 436us/sample - loss: 22.8233 - val_loss: 0.4748\n",
      "Epoch 193/1000\n",
      "595/595 [==============================] - 0s 406us/sample - loss: 34.0416 - val_loss: 0.4699\n",
      "Epoch 194/1000\n",
      "595/595 [==============================] - 0s 393us/sample - loss: 16.5903 - val_loss: 0.4773\n",
      "Epoch 195/1000\n",
      "595/595 [==============================] - 0s 420us/sample - loss: 33.0487 - val_loss: 0.4752\n",
      "Epoch 196/1000\n",
      "595/595 [==============================] - 0s 434us/sample - loss: 23.9186 - val_loss: 0.9812\n",
      "Epoch 197/1000\n",
      "595/595 [==============================] - 0s 401us/sample - loss: 71.8091 - val_loss: 1.0078\n",
      "Epoch 198/1000\n",
      "595/595 [==============================] - 0s 463us/sample - loss: 1276.8057 - val_loss: 0.8750\n",
      "Epoch 199/1000\n",
      "595/595 [==============================] - 0s 387us/sample - loss: 1372.6275 - val_loss: 0.6755\n",
      "Epoch 200/1000\n",
      "595/595 [==============================] - 0s 390us/sample - loss: 601.3460 - val_loss: 1.0418\n",
      "Epoch 201/1000\n",
      "595/595 [==============================] - 0s 437us/sample - loss: 496.9351 - val_loss: 1.0432\n",
      "Epoch 202/1000\n",
      "595/595 [==============================] - 0s 417us/sample - loss: 396.6626 - val_loss: 1.0333\n",
      "Epoch 203/1000\n",
      "595/595 [==============================] - 0s 400us/sample - loss: 229.4971 - val_loss: 0.9854\n",
      "Epoch 204/1000\n",
      "595/595 [==============================] - 0s 404us/sample - loss: 203.5264 - val_loss: 0.9940\n",
      "Epoch 205/1000\n",
      "595/595 [==============================] - 0s 425us/sample - loss: 113.5645 - val_loss: 1.0057\n",
      "Epoch 206/1000\n",
      "595/595 [==============================] - 0s 408us/sample - loss: 63.4507 - val_loss: 0.9876\n",
      "Epoch 207/1000\n",
      "595/595 [==============================] - 0s 404us/sample - loss: 133.0171 - val_loss: 0.9986\n",
      "Epoch 208/1000\n",
      "595/595 [==============================] - 0s 428us/sample - loss: 31.2383 - val_loss: 0.9948\n",
      "Epoch 209/1000\n",
      "595/595 [==============================] - 0s 440us/sample - loss: 55.7462 - val_loss: 1.0045\n",
      "Epoch 210/1000\n",
      "595/595 [==============================] - 0s 450us/sample - loss: 59.0785 - val_loss: 0.9976\n",
      "Epoch 211/1000\n",
      "595/595 [==============================] - 0s 431us/sample - loss: 34.1294 - val_loss: 0.9995\n",
      "Epoch 212/1000\n",
      "595/595 [==============================] - 0s 443us/sample - loss: 68.3707 - val_loss: 1.0035\n",
      "Epoch 213/1000\n",
      "595/595 [==============================] - 0s 455us/sample - loss: 1.7755 - val_loss: 1.0049\n",
      "Epoch 214/1000\n",
      "595/595 [==============================] - 0s 474us/sample - loss: 62.6654 - val_loss: 1.0001\n",
      "Epoch 215/1000\n",
      "595/595 [==============================] - 0s 479us/sample - loss: 7.3536 - val_loss: 1.0033\n",
      "Epoch 216/1000\n",
      "595/595 [==============================] - 0s 561us/sample - loss: 53.2094 - val_loss: 1.0005\n",
      "Epoch 217/1000\n",
      "595/595 [==============================] - 0s 480us/sample - loss: 3.0492 - val_loss: 0.9928\n",
      "Epoch 218/1000\n",
      "595/595 [==============================] - 0s 463us/sample - loss: 92.1121 - val_loss: 0.9974\n",
      "Epoch 219/1000\n",
      "595/595 [==============================] - 0s 574us/sample - loss: 6.8026 - val_loss: 1.0067\n",
      "Epoch 220/1000\n",
      "595/595 [==============================] - 0s 536us/sample - loss: 68.1057 - val_loss: 1.0019\n",
      "Epoch 221/1000\n",
      "595/595 [==============================] - 0s 595us/sample - loss: 15.3215 - val_loss: 0.9967\n",
      "Epoch 222/1000\n",
      "595/595 [==============================] - 0s 593us/sample - loss: 67.7350 - val_loss: 0.9970\n",
      "Epoch 223/1000\n",
      "595/595 [==============================] - 0s 555us/sample - loss: 10.7673 - val_loss: 1.0082\n",
      "Epoch 224/1000\n",
      "595/595 [==============================] - 0s 555us/sample - loss: 94.7019 - val_loss: 1.0046\n",
      "Epoch 225/1000\n",
      "595/595 [==============================] - 0s 602us/sample - loss: 40.9683 - val_loss: 0.9957\n",
      "Epoch 226/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595/595 [==============================] - 0s 626us/sample - loss: 48.8689 - val_loss: 1.0009\n",
      "Epoch 227/1000\n",
      "595/595 [==============================] - 0s 653us/sample - loss: 24.6810 - val_loss: 0.9985\n",
      "Epoch 228/1000\n",
      "595/595 [==============================] - 0s 595us/sample - loss: 40.8342 - val_loss: 1.0001\n",
      "Epoch 229/1000\n",
      "595/595 [==============================] - 0s 611us/sample - loss: 24.3809 - val_loss: 0.9991\n",
      "Epoch 230/1000\n",
      "595/595 [==============================] - 0s 651us/sample - loss: 28.4437 - val_loss: 1.0015\n",
      "Epoch 231/1000\n",
      "595/595 [==============================] - 0s 660us/sample - loss: 26.3264 - val_loss: 0.9982\n",
      "Epoch 232/1000\n",
      "595/595 [==============================] - 0s 795us/sample - loss: 36.8479 - val_loss: 1.0007\n",
      "Epoch 233/1000\n",
      "595/595 [==============================] - 0s 647us/sample - loss: 21.7039 - val_loss: 0.9970\n",
      "Epoch 234/1000\n",
      "595/595 [==============================] - 0s 744us/sample - loss: 41.3781 - val_loss: 1.0000\n",
      "Epoch 235/1000\n",
      "595/595 [==============================] - 0s 748us/sample - loss: 5.4519 - val_loss: 0.9960\n",
      "Epoch 236/1000\n",
      "595/595 [==============================] - 0s 679us/sample - loss: 38.6211 - val_loss: 1.0021\n",
      "Epoch 237/1000\n",
      "595/595 [==============================] - 0s 637us/sample - loss: 22.4816 - val_loss: 0.9963\n",
      "Epoch 238/1000\n",
      "595/595 [==============================] - 0s 599us/sample - loss: 38.3513 - val_loss: 1.0019\n",
      "Epoch 239/1000\n",
      "595/595 [==============================] - 0s 617us/sample - loss: 26.3930 - val_loss: 0.9972\n",
      "Epoch 240/1000\n",
      "595/595 [==============================] - 0s 624us/sample - loss: 37.7164 - val_loss: 1.0007\n",
      "Epoch 241/1000\n",
      "595/595 [==============================] - 0s 613us/sample - loss: 25.0621 - val_loss: 0.9981\n",
      "Epoch 242/1000\n",
      "595/595 [==============================] - 0s 614us/sample - loss: 33.6358 - val_loss: 1.0008\n",
      "Epoch 243/1000\n",
      "595/595 [==============================] - 0s 597us/sample - loss: 31.3157 - val_loss: 1.0011\n",
      "Epoch 244/1000\n",
      "595/595 [==============================] - 0s 609us/sample - loss: 20.7749 - val_loss: 1.0016\n",
      "Epoch 245/1000\n",
      "595/595 [==============================] - 0s 587us/sample - loss: 22.1259 - val_loss: 0.9971\n",
      "Epoch 246/1000\n",
      "595/595 [==============================] - 0s 670us/sample - loss: 38.1580 - val_loss: 0.9975\n",
      "Epoch 247/1000\n",
      "595/595 [==============================] - 0s 625us/sample - loss: 1.9356 - val_loss: 0.9969\n",
      "Epoch 248/1000\n",
      "595/595 [==============================] - 0s 657us/sample - loss: 37.6311 - val_loss: 0.9987\n",
      "Epoch 249/1000\n",
      "595/595 [==============================] - 0s 684us/sample - loss: 23.8080 - val_loss: 0.9990\n",
      "Epoch 250/1000\n",
      "595/595 [==============================] - 0s 644us/sample - loss: 17.5784 - val_loss: 1.0027\n",
      "Epoch 251/1000\n",
      "595/595 [==============================] - 0s 614us/sample - loss: 33.6525 - val_loss: 0.9989\n",
      "Epoch 252/1000\n",
      "595/595 [==============================] - 0s 667us/sample - loss: 14.2148 - val_loss: 1.0029\n",
      "Epoch 253/1000\n",
      "595/595 [==============================] - 0s 595us/sample - loss: 31.1530 - val_loss: 0.9973\n",
      "Epoch 254/1000\n",
      "595/595 [==============================] - 0s 580us/sample - loss: 32.7899 - val_loss: 1.0017\n",
      "Epoch 255/1000\n",
      "595/595 [==============================] - 0s 592us/sample - loss: 34.0927 - val_loss: 1.0020\n",
      "Epoch 00255: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x133c63c88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 构建神经网络层 1层LSTM层+3层Dense层\n",
    "lstm_input = Input(shape=(seq_length, input_dim), name='lstm_input') # input层不包括batch的shape\n",
    "lstm_output = LSTM(128, activation='tanh', dropout=0.5)(lstm_input)  # LSTM网络\n",
    "Dense_output_1 = Dense(64, activation='relu')(lstm_output)  \n",
    "Dense_output_2 = Dense(16, activation='relu')(Dense_output_1)  \n",
    "predictions = Dense(output_dim, activation='tanh')(Dense_output_2) \n",
    "model = Model(inputs=lstm_input, outputs=predictions)\n",
    "def customLoss(y, yhat):\n",
    "    return tf.reduce_mean((tf.math.abs(y - yhat)/(y+1e-7)))\n",
    "\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, verbose=1, mode='auto')\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss=customLoss)\n",
    "model.fit(x_train_sequence, y_train_sequence, validation_data=(x_val_sequence, y_val_sequence), batch_size=32, epochs=1000, callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看在 training data 上的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T06:46:47.631477Z",
     "start_time": "2020-07-28T06:46:42.579Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = y_scaler.inverse_transform(model.predict(x_train_sequence))\n",
    "y_train_truth = y_scaler.inverse_transform(y_train_sequence)\n",
    "plt.plot(y_pred, label=\"prediction\")\n",
    "plt.plot(y_train_truth, label=\"ground truth\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看在 validation data 上的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T06:46:47.632575Z",
     "start_time": "2020-07-28T06:46:42.592Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = y_scaler.inverse_transform(model.predict(x_val_sequence))\n",
    "y_val_truth = y_scaler.inverse_transform(y_val_sequence)\n",
    "plt.plot(y_pred, label=\"prediction\")\n",
    "plt.plot(y_val_truth, label=\"ground truth\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T06:46:47.633792Z",
     "start_time": "2020-07-28T06:46:42.596Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tushare as ts\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#参数设置/parameter setting\n",
    "timesteps = seq_length = 20 #时间窗/window length\n",
    "data_dim = 5 #输入数据维度/dimension of input data\n",
    "output_dim = 1 #输出数据维度/dimension of output data\n",
    "\n",
    "#数据准备/data preparation \n",
    "#变量选取Open,High,Low,Close,Volume，以浦发银行股票为例\n",
    "stock_data = ts.get_k_data('600000',start='2016-01-01',end='2018-11-20')\n",
    "xy = stock_data[['open','close','high','low','volume']]\n",
    "xy = np.array(xy.values)\n",
    "\n",
    "#切分训练集合测试集/split to train and testing\n",
    "train_size = int(len(xy) * 0.9)\n",
    "test_size = len(xy) - train_size\n",
    "xy_train, xy_test = np.array(xy[0:train_size]),np.array(xy[train_size:len(xy)])\n",
    "\n",
    "#对training set进行预处理\n",
    "scaler = MinMaxScaler()\n",
    "xy_train_new = scaler.fit_transform(xy_train)\n",
    "x_new = xy_train_new[:,0:5]\n",
    "y_new = xy_train_new[:,1]\n",
    "\n",
    "x = x_new\n",
    "y = y_new\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(y) - seq_length):\n",
    "    _x = x[i:i + seq_length]\n",
    "    _y = y[i + seq_length]  # Next close price\n",
    "    print(_x, \"->\", _y)\n",
    "    dataX.append(_x)\n",
    "    dataY.append(_y)\n",
    "\n",
    "#处理数据shape,准备进入神经网络层\n",
    "x_real = np.vstack(dataX).reshape(-1,seq_length,data_dim)\n",
    "y_real= np.vstack(dataY).reshape(-1,output_dim)\n",
    "print(x_real.shape)\n",
    "print(y_real.shape)\n",
    "dataX = x_real\n",
    "dataY = y_real\n",
    "\n",
    "trainX, trainY = dataX, dataY\n",
    "\n",
    "#对test set进行预处理，这里用了training的scaler\n",
    "xy_test_new = scaler.transform(xy_test)\n",
    "x_new = xy_test_new[:,0:5]\n",
    "y_new = xy_test_new[:,1]\n",
    "\n",
    "x = x_new\n",
    "y = y_new\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(y) - seq_length):\n",
    "    _x = x[i:i + seq_length]\n",
    "    _y = y[i + seq_length]  # Next price change\n",
    "    print(_x, \"->\", _y)\n",
    "    dataX.append(_x)\n",
    "    dataY.append(_y)\n",
    "\n",
    "#处理数据shape,准备进入神经网络层\n",
    "x_real = np.vstack(dataX).reshape(-1,seq_length,data_dim)\n",
    "y_real= np.vstack(dataY).reshape(-1,output_dim)\n",
    "print(x_real.shape)\n",
    "print(y_real.shape)\n",
    "dataX = x_real\n",
    "dataY = y_real\n",
    "\n",
    "testX, testY = dataX, dataY\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 构建神经网络层 1层LSTM层+3层Dense层\n",
    "lstm_input = Input(shape=(seq_length, data_dim), name='lstm_input')#shape: 形状元组（整型）不包括batch size。表示了预期的输入将是一批（seq_len,data_dim）的向量。\n",
    "lstm_output = LSTM(128, activation='tanh', dropout=0.5)(lstm_input)#LSTM网络\n",
    "#units: Positive integer,dimensionality of the output space.\n",
    "#dropout: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.\n",
    "Dense_output_1 = Dense(64, activation='relu')(lstm_output)#全连接网络\n",
    "Dense_output_2 = Dense(16, activation='relu')(Dense_output_1)#全连接网络\n",
    "predictions = Dense(output_dim, activation='tanh')(Dense_output_2)#全连接网络\n",
    "\n",
    "model = Model(inputs=lstm_input, outputs=predictions)\n",
    "#This model will include all layers required in the computation of output given input.\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "#Configures the model for training.\n",
    "#optimizer: String (name of optimizer) or optimizer instance. See optimizers.\n",
    "#loss: String (name of objective function) or objective function.The loss value will be minimized by the model.\n",
    "#metrics: List of metrics to be evaluated by the model during training and testing. Typically you will use  metrics=['accuracy'].\n",
    "model.fit(trainX, trainY, batch_size=len(trainX), epochs=100, verbose=2)\n",
    "#Trains the model for a given number of epochs (iterations on a dataset).\n",
    "#verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "\n",
    "# 保存模型\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看在 training data 上的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T06:46:47.634837Z",
     "start_time": "2020-07-28T06:46:42.610Z"
    }
   },
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "trainPredict1 = trainPredict * scaler.data_range_[1] + scaler.data_min_[1]\n",
    "trainY1 = trainY * scaler.data_range_[1] + scaler.data_min_[1]\n",
    "plt.plot(trainY1,color='blue', label='ground truth')\n",
    "plt.plot(trainPredict1,color='orange', label=\"prediction\")\n",
    "plt.legend()\n",
    "plt.title(\"train\")\n",
    "plt.show()\n",
    "print(max(abs(trainPredict1 - trainY1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T06:46:47.635950Z",
     "start_time": "2020-07-28T06:46:42.622Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 载入模型\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "testPredict = model.predict(testX)\n",
    "testPredict1 = testPredict * scaler.data_range_[1] + scaler.data_min_[1]\n",
    "testY1 = testY * scaler.data_range_[1] + scaler.data_min_[1]\n",
    "plt.plot(testY1,color='blue', label=\"ground truth\")\n",
    "plt.plot(testPredict1,color='orange', label=\"prediction\")\n",
    "plt.legend()\n",
    "plt.title(\"val\")\n",
    "plt.show()\n",
    "print(max(abs(testPredict1 - testY1)))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('tensorflow2': conda)",
   "language": "python",
   "name": "python361064bittensorflow2conda916f6dc8789a43e39b82205c8a731f83"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
