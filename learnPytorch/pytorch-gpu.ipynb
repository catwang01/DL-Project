{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[toc]\n",
    "\n",
    "# Pytorch GPU 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单GPU训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看 gpu 是否可用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T10:19:38.035380Z",
     "start_time": "2020-07-25T10:19:38.030133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 gpu 训练的时候，有三点需要注意\n",
    "\n",
    "1. 将模型放到 gpu 上。只需要将最终的模型放到 gpu 上即可，模型中包含的层会被自动放到 gpu 上。\n",
    "2. 将训练数据放到 gpu 上\n",
    "3. 将输出数据从gpu上取下来"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有两种方式可以将模型放到 gpu 上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `model = model.to(\"cuda:0\")`\n",
    "2. `model = model.cuda()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，上面的模型修改不是原地的，需要进行赋值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 tensor.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T10:50:30.666383Z",
     "start_time": "2020-07-25T10:50:30.605956Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import load_boston\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "boston = load_boston()\n",
    "x = torch.Tensor(boston['data'])\n",
    "y = torch.Tensor(boston['target'])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torch.nn.Linear(13, 1)\n",
    "model = model.to(device)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    x = x.to(device)\n",
    "    yhat = model(x).view(-1)\n",
    "    mse = loss(y, yhat)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    mse.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T10:51:39.378278Z",
     "start_time": "2020-07-25T10:51:39.375744Z"
    }
   },
   "source": [
    "### 使用 tensor.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T10:51:21.666792Z",
     "start_time": "2020-07-25T10:51:21.611921Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import load_boston\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "boston = load_boston()\n",
    "x = torch.Tensor(boston['data'])\n",
    "y = torch.Tensor(boston['target'])\n",
    "\n",
    "model = torch.nn.Linear(13, 1)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    yhat = model(x).view(-1)\n",
    "    mse = loss(y, yhat)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    mse.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何判断 model 和 tensor 所在的 device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于 tensor 来说，可以用 tensor.device 来查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T03:25:38.973467Z",
     "start_time": "2020-08-20T03:25:38.970110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 2)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于 model 来说，可以查看 model.parameters 所在的 device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T03:25:37.409541Z",
     "start_time": "2020-08-20T03:25:37.403652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "class TestModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "model = TestModel(2, 3)\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在类中使用中间变量时需要手动 to_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请看下面的代码，这个代码在 gpu 条件下会报错 `RuntimeError: Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T03:01:18.352370Z",
     "start_time": "2020-08-20T03:01:18.340139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2704,  0.3590, -0.7894],\n",
      "         [ 0.1826,  0.0097,  0.1279],\n",
      "         [ 0.2195,  0.1916, -0.1293]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[1]\n",
    "        hidden = torch.zeros([1, batch_size, self.hidden_dim]) # 这个没有 to.device\n",
    "        _, hidden = self.rnn(x, hidden)\n",
    "        logits = self.fc(hidden.squeeze(1))\n",
    "        return logits\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 3\n",
    "seq_len = 4\n",
    "input_dim = 10\n",
    "output_dim = 3\n",
    "hidden_dim = 5\n",
    "\n",
    "x = torch.randn(seq_len, batch_size, input_dim)\n",
    "x = x.to(device)\n",
    "\n",
    "rnn = SimpleRNN(input_dim, hidden_dim, output_dim)\n",
    "rnn = rnn.to(device)\n",
    "output = rnn(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.to(device) 的时候会将 model.parameters() 中的变量也调用 to(device)。但是 hidden 是在 forward 中间创建的变量，因此不会自动对它调用 to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T03:01:05.593782Z",
     "start_time": "2020-08-20T03:01:05.589758Z"
    }
   },
   "source": [
    "解决方法是想办法对 hidden 手动调用 to(device)，下面给出两种可行的解决方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解决方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在运行时获取 device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T03:02:32.729145Z",
     "start_time": "2020-08-20T03:02:32.723001Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[1]\n",
    "        \n",
    "        # self.parameters() 是一个 generator，需要 next 得到它的一个元素\n",
    "        device = next(self.parameters()).device\n",
    "        hidden = torch.zeros([1, batch_size, self.hidden_dim]) # 这个没有 to.device\n",
    "        hidden = hidden.to(device)\n",
    "        \n",
    "        _, hidden = self.rnn(x, hidden)\n",
    "        logits = self.fc(hidden.squeeze(1))\n",
    "        return logits\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 3\n",
    "seq_len = 4\n",
    "input_dim = 10\n",
    "output_dim = 3\n",
    "hidden_dim = 5\n",
    "\n",
    "x = torch.randn(seq_len, batch_size, input_dim)\n",
    "x = x.to(device)\n",
    "\n",
    "rnn = SimpleRNN(input_dim, hidden_dim, output_dim)\n",
    "rnn = rnn.to(device)\n",
    "output = rnn(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化时就决定device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一种可行的解决方式是将 device 作为一个参数，在初始化的时候就传递"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T03:03:30.307723Z",
     "start_time": "2020-08-20T03:03:30.297169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1413,  0.0965,  0.2120],\n",
      "         [-0.4704,  0.0670,  0.2349],\n",
      "         [ 0.1077,  0.5577, -0.1399]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[1]\n",
    "        \n",
    "        # self.parameters() 是一个 generator，需要 next 得到它的一个元素\n",
    "        hidden = torch.zeros([1, batch_size, self.hidden_dim]) # 这个没有 to.device\n",
    "        hidden = hidden.to(self.device)\n",
    "        \n",
    "        _, hidden = self.rnn(x, hidden)\n",
    "        logits = self.fc(hidden.squeeze(1))\n",
    "        return logits\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 3\n",
    "seq_len = 4\n",
    "input_dim = 10\n",
    "output_dim = 3\n",
    "hidden_dim = 5\n",
    "\n",
    "x = torch.randn(seq_len, batch_size, input_dim)\n",
    "x = x.to(device)\n",
    "\n",
    "rnn = SimpleRNN(input_dim, hidden_dim, output_dim, device)\n",
    "rnn = rnn.to(device)\n",
    "output = rnn(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T10:18:51.034747Z",
     "start_time": "2020-07-25T10:18:51.026460Z"
    }
   },
   "source": [
    "# References\n",
    "1. [(1 封私信 / 18 条消息) 如何在pytorch中正确使用GPU进行训练？ - 知乎](https://www.zhihu.com/question/345418003)\n",
    "\n",
    "2. [(2条消息)pytorch查看torch.Tensor和model是否在CUDA上_WYXHAHAHA123的博客-CSDN博客](https://blog.csdn.net/WYXHAHAHA123/article/details/86596981)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
