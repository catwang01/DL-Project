{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[toc]\n",
    "\n",
    "# Pytorch 卷积相关操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- kernel_size, stride, padding, dilation 四个参数可以是 int，也可以是一个二维 tuple。如果是 int，表示两个维度大小相等。\n",
    "\n",
    ">The parameters kernel_size, stride, padding, dilation can either be:\n",
    ">\n",
    ">a single int – in which case the same value is used for the height and width dimension\n",
    ">\n",
    ">a tuple of two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension\n",
    "\n",
    "- shape\n",
    "\n",
    "- input: $\\left(N, C_{i n}, H_{i n}, W_{i n}\\right)$\n",
    "- output: $\\left(N, C_{\\text {out }}, H_{\\text {out }}, W_{\\text {out }}\\right)$ where\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&H_{out}=\\left\\lfloor\\frac{H_{i n}+2 \\times \\text { padding }[0]-\\operatorname{dilation}[0] \\times(\\text { kernel } \\operatorname{size}[0]-1)-1}{\\operatorname{stride}[0]}+1\\right\\rfloor .\\\\\n",
    "&W_{out}=\\left\\lfloor\\frac{W_{i n}+2 \\times \\text { padding }[1]-\\text { dilation }[1] \\times(\\text { kernel size }[1]-1)-1}{\\text { stride }[1]}+1\\right\\rfloor.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "注意是向下取整。即上面的除法可以看做 floor division\n",
    "\n",
    "关于 dilation 的作用，可以看 [pytorch的函数中的dilation参数的作用 - 慢行厚积 - 博客园](https://www.cnblogs.com/wanghui-garcia/p/10775367.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maxpool\n",
    "\n",
    "### torch.nn.MaxPool2d\n",
    "\n",
    "```\n",
    "torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "```\n",
    "\n",
    "这些参数和 `torch.nn.Conv2d` 的相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.functional.max_pool2d\n",
    "\n",
    "由于 MaxPool 层不需要训练，因此它常常是以 torch.nn.functional.max_pool2d 的形式来出现，而不是 torch.nn.MaxPool2d\n",
    "\n",
    "```\n",
    "max_pool2d\n",
    "torch.nn.functional.max_pool2d(*args, **kwargs)\n",
    "```\n",
    "\n",
    "Applies a 2D max pooling over an input signal composed of several input planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References\n",
    "1. [torch.nn — PyTorch master documentation](https://pytorch.org/docs/stable/nn.html?highlight=conv2d#torch.nn.Conv2d)\n",
    "2. [pytorch的函数中的dilation参数的作用 - 慢行厚积 - 博客园](https://www.cnblogs.com/wanghui-garcia/p/10775367.html)\n",
    "3. [torch.nn — PyTorch master documentation](https://pytorch.org/docs/stable/nn.html#torch.nn.MaxPool2d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
