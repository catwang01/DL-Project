{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[toc]\n",
    "\n",
    "# Pytorch torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchtext概述\n",
    "\n",
    "torchtext预处理流程：\n",
    "\n",
    "1. 定义Field：声明如何处理数据\n",
    "2. 定义Dataset：得到数据集，此时数据集里每一个样本是一个 经过 Field声明的预处理 预处理后的 wordlist\n",
    "3. 建立vocab：在这一步建立词汇表，词向量(word embeddings)\n",
    "4. 构造Iterator，用来分批次训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field对象\n",
    "\n",
    "Field对象指定要如何处理某个字段."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Dataset定义数据源信息."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterator\n",
    "\n",
    "迭代器返回模型所需要的处理后的数据.迭代器主要分为Iterator, BucketIerator, BPTTIterator三种。\n",
    "\n",
    "*   Iterator：标准迭代器\n",
    "*   BucketIerator：相比于标准迭代器，会将类似长度的样本当做一批来处理，因为在文本处理中经常会需要将每一批样本长度补齐为当前批中最长序列的长度，因此当样本长度差别较大时，使用BucketIerator可以带来填充效率的提高。除此之外，我们还可以在Field中通过 fix_length参数来对样本进行截断补齐操作。\n",
    "*   BPTTIterator: 基于BPTT(基于时间的反向传播算法)的迭代器，一般用于语言模型中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sequential – Whether the datatype represents sequential data. If False, no tokenization is applied. Default: True.\n",
    "\n",
    "- use_vocab – Whether to use a Vocab object. If False, the data in this field should already be numerical. Default: True.\n",
    "\n",
    "- init_token – A token that will be prepended to every example using this field, or None for no initial token. Default: None.\n",
    "\n",
    "- eos_token – A token that will be appended to every example using this field, or None for no end-of-sentence token. Default: None.\n",
    "\n",
    "- fix_length – A fixed length that all examples using this field will be padded to, or None for flexible sequence lengths. Default: None.\n",
    "\n",
    "- dtype – The torch.dtype class that represents a batch of examples of this kind of data. Default: torch.long.\n",
    "\n",
    "- preprocessing – The Pipeline that will be applied to examples using this field after tokenizing but before numericalizing. Many Datasets replace this attribute with a custom preprocessor. Default: None.\n",
    "\n",
    "- postprocessing – A Pipeline that will be applied to examples using this field after numericalizing but before the numbers are turned into a Tensor. The pipeline function takes the batch as a list, and the field’s Vocab. Default: None.\n",
    "\n",
    "- lower – Whether to lowercase the text in this field. Default: False.\n",
    "\n",
    "- tokenize – The function used to tokenize strings using this field into sequential examples. If “spacy”, the SpaCy tokenizer is used. If a non-serializable function is passed as an argument, the field will not be able to be serialized. Default: string.split.\n",
    "\n",
    "- tokenizer_language – The language of the tokenizer to be constructed. Various languages currently supported only in SpaCy.\n",
    "\n",
    "- include_lengths – Whether to return a tuple of a padded minibatch and a list containing the lengths of each examples, or just a padded minibatch. Default: False.\n",
    "\n",
    "- batch_first – Whether to produce tensors with the batch dimension first. Default: False.\n",
    "\n",
    "- pad_token – The string token used as padding. Default: “<pad>”.\n",
    "\n",
    "- unk_token – The string token used to represent OOV words. Default: “<unk>”.\n",
    "\n",
    "- pad_first – Do the padding of the sequence at the beginning. Default: False.\n",
    "\n",
    "- truncate_first – Do the truncating of the sequence at the beginning. Default: False\n",
    "\n",
    "- stop_words – Tokens to discard during the preprocessing step. Default: None\n",
    "\n",
    "- is_target – Whether this field is a target variable. Affects iteration over batches. Default: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "TEXT = data.Field(sequential=True, lower=True, fix_length=200)\n",
    "LABEL = data.Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-55ef565aff2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0m设置skip_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m不然它会把列名也当一个数据处理\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \"\"\"\n\u001b[1;32m----> 6\u001b[1;33m train,val = data.TabularDataset.splits(\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mskip_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         fields=[('PhraseId',None),('SentenceId',None),('Phrase', TEXT), ('Sentiment', LABEL)])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "我们不需要 'PhraseId' 和 'SentenceId'这两列, 所以我们给他们的field传递 None\n",
    "如果你的数据有列名，如我们这里的'Phrase','Sentiment',...\n",
    "设置skip_header=True,不然它会把列名也当一个数据处理\n",
    "\"\"\"\n",
    "train,val = data.TabularDataset.splits(\n",
    "        path='.', train='train.csv',validation='val.csv', format='csv',skip_header=True,\n",
    "        fields=[('PhraseId',None),('SentenceId',None),('Phrase', TEXT), ('Sentiment', LABEL)])\n",
    "\n",
    "test = data.TabularDataset('test.tsv', format='tsv',skip_header=True,\n",
    "        fields=[('PhraseId',None),('SentenceId',None),('Phrase', TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a375f607de6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhrase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "print(train[5])\n",
    "print(train[5].__dict__.keys())\n",
    "print(train[5].Phrase,train[0].Sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到第6行的输入，它是一个Example对象。Example对象绑定了一行中的所有属性，可以看到，句子已经被分词了，但是没有转化为数字。\n",
    "\n",
    "这是因为我们还没有建立vocab，我们将在下一步建立vocab。\n",
    "\n",
    "Torchtext可以将词转化为数字，但是它需要被告知需要被处理的全部范围的词。我们可以用下面这行代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab 建立之后就可以将词和数字之间相互转化了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TEXT.vocab.itos[1510])\n",
    "print(TEXT.vocab.stoi['bore'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在建立词表的过程中，默认 `<unk>` 的 index 是 0，然后依次添加其他词语。因此会在有的代码中出现下面的对齐下标的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_iter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-752560b0d753>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhrase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhrase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_iter' is not defined"
     ]
    }
   ],
   "source": [
    "for batch in data_iter:\n",
    "    feature, target = batch.text, batch.label\n",
    "    feature.t_(), target.sub_(1)  # batch first, index align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, csv_path, text_field, label_field, test=False, aug=False, **kwargs):\n",
    "        \n",
    "        csv_data = pd.read_csv(csv_path)\n",
    "        \n",
    "        # 数据处理操作格式\n",
    "        fields = [(\"id\", None),(\"text\", text_field), (\"label\", label_field)]\n",
    "        \n",
    "        examples = []\n",
    "        if test:\n",
    "            # 如果为测试集，则不加载标签\n",
    "            for text in tqdm(csv_data['text']):\n",
    "                examples.append(data.Example.fromlist([None, text, None], fields))\n",
    "        else:\n",
    "            for text, label in tqdm(zip(csv_data['text'], csv_data['label'])):\n",
    "                # 数据增强\n",
    "                if aug:\n",
    "                    rate = random.random()\n",
    "                    if rate > 0.5:\n",
    "                        text = self.dropout(text)\n",
    "                    else:\n",
    "                        text = self.shuffle(text)\n",
    "                examples.append(data.Example.fromlist([None, text, label], fields))\n",
    "                \n",
    "        # 上面是一些预处理操作，此处调用super调用父类构造方法，产生标准Dataset\n",
    "        # super(MyDataset, self).__init__(examples, fields, **kwargs)\n",
    "        super(MyDataset, self).__init__(examples, fields)\n",
    "\n",
    "    def shuffle(self, text):\n",
    "        # 序列随机排序\n",
    "        text = np.random.permutation(text.strip().split())\n",
    "        return ' '.join(text)\n",
    "\n",
    "    def dropout(self, text, p=0.5):\n",
    "        # 随机删除一些文本\n",
    "        text = text.strip().split()\n",
    "        len_ = len(text)\n",
    "        indexs = np.random.choice(len_, int(len_ * p))\n",
    "        for i in indexs:\n",
    "            text[i] = ''\n",
    "        return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-330745831881>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_iter = data.BucketIterator(train, batch_size=128, sort_key=lambda x: len(x.Phrase), \n\u001b[0m\u001b[0;32m      2\u001b[0m                                  shuffle=True,device=DEVICE)\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m val_iter = data.BucketIterator(val, batch_size=128, sort_key=lambda x: len(x.Phrase), \n\u001b[0;32m      5\u001b[0m                                  shuffle=True,device=DEVICE)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train_iter = data.BucketIterator(train, batch_size=128, sort_key=lambda x: len(x.Phrase), \n",
    "                                 shuffle=True,device=DEVICE)\n",
    "\n",
    "val_iter = data.BucketIterator(val, batch_size=128, sort_key=lambda x: len(x.Phrase), \n",
    "                                 shuffle=True,device=DEVICE)\n",
    "\n",
    "# 在 test_iter , sort一定要设置成 False, 要不然会被 torchtext 搞乱样本顺序\n",
    "test_iter = data.Iterator(dataset=test, batch_size=128, train=False,\n",
    "                          sort=False, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的属性名就是我们之前在 fields 中设置的属性名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_iter:\n",
    "    data = batch.Phrase\n",
    "    label = batch.Sentiment\n",
    "    print(batch.Phrase.shape)\n",
    "    print(batch.Phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API\n",
    "\n",
    "#### vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numericalize\n",
    "\n",
    "Field.numericalize([['eward', 'elric']]) 将词语转化为 one-hot 表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. [TorchText用法示例及完整代码_nlpuser的博客-CSDN博客](https://blog.csdn.net/nlpuser/article/details/88067167)\n",
    "2. [Torchtext使用教程 文本数据处理 - 林震宇 - 博客园](https://www.cnblogs.com/linzhenyu/p/13277552.html)\n",
    "3. [Torchtext使用教程_NLP Tutorial-CSDN博客](https://blog.csdn.net/JWoswin/article/details/92821752)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
