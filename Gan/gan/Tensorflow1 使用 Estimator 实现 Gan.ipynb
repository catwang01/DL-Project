{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Tensorflow Gan 实现 Estimator\n",
    "tags: 小书匠,Tensorflow,Tensorflow1,gan,estimator\n",
    "grammar_cjkRuby: true\n",
    "# renderNumberedHeading: true\n",
    "---\n",
    "\n",
    "[toc!]\n",
    "\n",
    "# Tensorflow Gan 实现 Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个实现和大多数实现不同。在原始的 Gan 论文中，在更新完 Discriminator 之后，generator 需要重新抽样并计算梯度，好多实现中并没有重新抽样这一步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import io\n",
    "from tensorflow.keras.layers import Dense\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#该函数用于输出生成图片\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_Z(shape):\n",
    "    return tf.random.normal(shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意，这里要将图片范围缩小到 [0, 1] 上\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "x_train = x_train.reshape(-1, 28 * 28)\n",
    "x_test = x_test.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    x_true = features\n",
    "    Generator = tf.keras.Sequential([\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(784, activation='sigmoid'), # 最后接一个 sigmoid，将输出范围也缩小到 [0, 1] 上，和 x 的范围相同\n",
    "    ])\n",
    "\n",
    "    Discriminator = tf.keras.Sequential([\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    input_shape = tf.shape(x_true)\n",
    "    x_fake = Generator(sample_Z(input_shape))\n",
    "    D_logits_fake = Discriminator(x_fake)\n",
    "    D_logits_true = Discriminator(x_true)\n",
    "    \n",
    "    tf.summary.image(\"fake\", tf.reshape(x_fake, (-1, 28, 28, 1)))\n",
    "    tf.summary.image(\"true\", tf.reshape(x_true, (-1, 28, 28, 1)))\n",
    "\n",
    "    D_loss_positive = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=tf.ones_like(D_logits_true), logits=D_logits_true))\n",
    "    D_loss_negative = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=tf.zeros_like(D_logits_fake), logits=D_logits_fake))\n",
    "    D_loss = D_loss_positive + D_loss_negative\n",
    "\n",
    "    D_global_step = tf.Variable(0, dtype=tf.int64, trainable=False)\n",
    "    G_global_step = tf.Variable(0, dtype=tf.int64, trainable=False)\n",
    "    \n",
    "    global_step = tf.train.get_global_step()\n",
    "    \n",
    "    D_train_op = tf.train.AdamOptimizer().minimize(D_loss,\n",
    "                                                   var_list=Discriminator.trainable_variables,\n",
    "                                                   global_step=D_global_step)\n",
    "\n",
    "    # 先优化 D，然后再优化 G\n",
    "    with tf.control_dependencies([D_train_op]):\n",
    "        new_D_logits_fake = Discriminator(Generator(sample_Z(input_shape)))\n",
    "        G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(new_D_logits_fake),\n",
    "                                                                        logits=new_D_logits_fake))\n",
    "        G_train_op = tf.train.AdamOptimizer().minimize(G_loss,\n",
    "                                                           var_list=Generator.trainable_variables,\n",
    "                                                           global_step=G_global_step)\n",
    "        # 手动更新 global_step\n",
    "        # 因为我们要 minimize 两个 loss，如果要自动更新 global_step，会导致 global_step 是实际的两倍\n",
    "        update_global_step = tf.assign(global_step, G_global_step)\n",
    "        \n",
    "        train_op = tf.group(G_train_op, update_global_step)\n",
    "        \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\"x_fake\": x_fake, \"D_logits_fake\": D_logits_fake}\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=predictions)\n",
    "\n",
    "    elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          loss=G_loss,\n",
    "                                          train_op=train_op)\n",
    "\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        metrics = {\n",
    "            \"acc_fake\": tf.metrics.accuracy(labels=tf.zeros_like(D_logits_fake),\n",
    "                                            predictions=tf.cast(tf.nn.sigmoid(D_logits_fake) > 0.5, tf.int32)),\n",
    "            \"acc_true\": tf.metrics.accuracy(labels=tf.ones_like(D_logits_true),\n",
    "                                            predictions=tf.cast(tf.nn.sigmoid(D_logits_true) > 0.5, tf.int32)),\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          loss=D_loss,\n",
    "                                          eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 400, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x142d1e208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 400 or save_checkpoints_secs None.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = './model'\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 400\n",
    "LR = 0.0001\n",
    "\n",
    "def input_fn(x, epochs=1, batch_size=32, istrain=False):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "    if istrain:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset \n",
    "\n",
    "config = tf.estimator.RunConfig(save_checkpoints_steps=400)\n",
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn, # 这里需要一个函数\n",
    "    model_dir=model_dir, \n",
    "    config=config\n",
    ")\n",
    "\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=functools.partial(input_fn,\n",
    "                               x_train,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               istrain=True,\n",
    "                               epochs=EPOCHS), \n",
    "    max_steps=20000,\n",
    ")\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=functools.partial(input_fn,\n",
    "                               x_test,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               istrain=False,\n",
    "                               epochs=EPOCHS), \n",
    "    throttle_secs=5,\n",
    ")\n",
    "\n",
    "tf.estimator.train_and_evaluate(\n",
    "    estimator,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- https://github.com/jiqizhixin/ML-Tutorial-Experiment/blob/ce316d55439859e8aaf10903a55b52066e20146c/Experiments/tf_GAN.ipynb\n",
    "- http://localhost:8888/lab/tree/DL-Project/Gan/gan/Tensorflow1%20%E4%BD%BF%E7%94%A8%20Estimator%20%E5%AE%9E%E7%8E%B0%20Gan.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
