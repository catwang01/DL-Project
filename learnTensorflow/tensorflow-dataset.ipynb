{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[toc]\n",
    "\n",
    "# Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from_generator\n",
    "\n",
    "下面的代码展示如何使用 `from_generator` 来生成成对数据集。对于只有 X 而没有 y 的数据集，只需要进行小修改即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T04:25:47.583265Z",
     "start_time": "2020-07-25T04:25:45.113442Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "__iter__() is only supported inside of tf.function or when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-42e7863b18c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 这里生成的 dataset 还没有分 batch，使用 .batch() 设置batch_size为 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2034\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIteratorV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n\u001b[0m\u001b[1;32m    344\u001b[0m                          \"or when eager execution is enabled.\")\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: __iter__() is only supported inside of tf.function or when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__) # 2.2.0\n",
    "\n",
    "# 生成数据集\n",
    "x_train = np.random.uniform(0, 1, [10, 3])\n",
    "y_train = np.random.randint(0, 10, [10, ])\n",
    "\n",
    "# 定义生成器\n",
    "def batch_generator():\n",
    "    n_samples = x_train.shape[0]\n",
    "    for i in range(n_samples):\n",
    "        yield x_train[i], y_train[i]\n",
    "\n",
    "# 使用 生成器\n",
    "train_dataset = tf.data.Dataset.from_generator(batch_generator, (tf.float32, tf.int32))\n",
    "\n",
    "# 设置epoch为2\n",
    "train_dataset = train_dataset.repeat(2)\n",
    "# 这里生成的 dataset 还没有分 batch，使用 .batch() 设置batch_size为 5\n",
    "train_dataset = train_dataset.batch(5)\n",
    "for x, y in train_dataset:\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**其中有一个坑。 generator 函数返回的应该是一个 tuple 对象，而不是一个 list 对象。**\n",
    "\n",
    "如果将上面的 `batch_generator` 修改成下面的样子，则会报错 `TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.int32), but the yielded element was [array([0.71891118, 0.55713524, 0.83305131]), 2].`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成器\n",
    "def batch_generator():\n",
    "    n_samples = x_train.shape[0]\n",
    "    for i in range(n_samples):\n",
    "        yield [x_train[i], y_train[i]] # Error!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成器传参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时，我们想在创建生成器的时候传入参数，此时可以使用 args 来传入参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T16:06:01.984096Z",
     "start_time": "2020-08-01T16:06:01.941598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "tf.Tensor(\n",
      "[[0.8848176  0.32335648 0.11673396]\n",
      " [0.635564   0.9853623  0.34263027]\n",
      " [0.525984   0.10160588 0.93273044]\n",
      " [0.9645629  0.07456936 0.7372238 ]], shape=(4, 3), dtype=float32) tf.Tensor([8 8 9 9], shape=(4,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0.4510364  0.50084555 0.9311134 ]\n",
      " [0.00404259 0.4692437  0.44436535]\n",
      " [0.8974993  0.8824926  0.99141914]\n",
      " [0.9761399  0.7577163  0.5177157 ]], shape=(4, 3), dtype=float32) tf.Tensor([2 3 2 8], shape=(4,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0.04106055 0.00701396 0.10839242]\n",
      " [0.660547   0.9916826  0.9171571 ]], shape=(2, 3), dtype=float32) tf.Tensor([7 8], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__) # 2.2.0\n",
    "\n",
    "# 生成数据集\n",
    "x_train = np.random.uniform(0, 1, [10, 3])\n",
    "y_train = np.random.randint(0, 10, [10, ])\n",
    "\n",
    "# 定义生成器\n",
    "def batch_generator(batch_size):\n",
    "    n_samples = x_train.shape[0]\n",
    "    start = 0\n",
    "    while start < n_samples:\n",
    "        yield x_train[start: start+batch_size], y_train[start: start+batch_size]\n",
    "        start += batch_size\n",
    "\n",
    "# 使用 生成器\n",
    "train_dataset = tf.data.Dataset.from_generator(batch_generator, (tf.float32, tf.int32), args=(4,)) # 注意，一个参数时要写作 (4,) 而不是 (4)\n",
    "\n",
    "for x, y in train_dataset:\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取一个 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T17:58:17.142543Z",
     "start_time": "2020-08-01T17:58:17.122786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.8848176 , 0.32335648, 0.11673396],\n",
       "        [0.635564  , 0.9853623 , 0.34263027],\n",
       "        [0.525984  , 0.10160588, 0.93273044],\n",
       "        [0.9645629 , 0.07456936, 0.7372238 ]], dtype=float32),\n",
       " array([8, 8, 9, 9], dtype=int32))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator = train_dataset.as_numpy_iterator()\n",
    "iterator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from_tensor_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "tf.Tensor(\n",
      "[[0.63026611 0.84018849 0.96822053]\n",
      " [0.00950266 0.82345767 0.14237034]\n",
      " [0.3628959  0.36985282 0.76039462]\n",
      " [0.60812065 0.30927249 0.17130571]\n",
      " [0.27561707 0.12677321 0.7169283 ]], shape=(5, 3), dtype=float64) tf.Tensor([6 7 0 5 8], shape=(5,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[0.32115764 0.44327448 0.6138822 ]\n",
      " [0.71774647 0.05496469 0.48456999]\n",
      " [0.00653992 0.61188734 0.01731185]\n",
      " [0.9451552  0.08030777 0.47051986]\n",
      " [0.06737426 0.55813358 0.97273234]], shape=(5, 3), dtype=float64) tf.Tensor([7 3 7 1 5], shape=(5,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[0.63026611 0.84018849 0.96822053]\n",
      " [0.00950266 0.82345767 0.14237034]\n",
      " [0.3628959  0.36985282 0.76039462]\n",
      " [0.60812065 0.30927249 0.17130571]\n",
      " [0.27561707 0.12677321 0.7169283 ]], shape=(5, 3), dtype=float64) tf.Tensor([6 7 0 5 8], shape=(5,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[0.32115764 0.44327448 0.6138822 ]\n",
      " [0.71774647 0.05496469 0.48456999]\n",
      " [0.00653992 0.61188734 0.01731185]\n",
      " [0.9451552  0.08030777 0.47051986]\n",
      " [0.06737426 0.55813358 0.97273234]], shape=(5, 3), dtype=float64) tf.Tensor([7 3 7 1 5], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__) # 2.2.0\n",
    "\n",
    "# 生成数据集\n",
    "x_train = np.random.uniform(0, 1, [10, 3])\n",
    "y_train = np.random.randint(0, 10, [10, ])\n",
    "\n",
    "\n",
    "# 使用 生成器\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "\n",
    "# 设置epoch为2，设置batch_size为 5\n",
    "train_dataset = train_dataset.repeat(2).batch(5)\n",
    "for x, y in train_dataset:\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. [(1条消息)tf.dataset 使用 python generator 加载和预处理数据，dataset.map 对数据进行额外加工_ONE_SIX_MIX的专栏-CSDN博客_dataset.map](https://blog.csdn.net/ONE_SIX_MIX/article/details/80633187)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:tars]",
   "language": "python",
   "name": "conda-env-tars-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
