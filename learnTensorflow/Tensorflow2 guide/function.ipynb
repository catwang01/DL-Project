{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Tensorflow2 function\n",
    "tags: 小书匠,tensorflow2,function\n",
    "grammar_cjkRuby: true\n",
    "renderNumberedHeading: true\n",
    "---\n",
    "\n",
    "[toc]\n",
    "\n",
    "# Tensorflow2 function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J122XQYG7W6w"
   },
   "source": [
    "In TensorFlow 2, eager execution is turned on by default. The user interface is intuitive and flexible (running one-off operations is much easier\n",
    "and faster), but this can come at the expense of performance and deployability.\n",
    "\n",
    "You can use `tf.function` to make graphs out of your programs. It is a transformation tool that creates Python-independent dataflow graphs out of your Python code. This will help you create performant and portable models, and it is required to use `SavedModel`.\n",
    "\n",
    "This guide will help you conceptualize how `tf.function` works under the hood so you can use it effectively.\n",
    "\n",
    "The main takeaways and recommendations are:\n",
    "\n",
    "- Debug in eager mode, then decorate with `@tf.function`.\n",
    "- Don't rely on Python side effects like object mutation or list appends.\n",
    "- `tf.function` works best with TensorFlow ops; NumPy and Python calls are converted to constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjvqpgepHJPd"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "otIdN1TS8N7S",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0xDjO4SHLUD"
   },
   "source": [
    "Define a helper function to demonstrate the kinds of errors you might encounter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "D25apou9IOXa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "import contextlib\n",
    "\n",
    "# Some helper code to demonstrate the kinds of errors you might encounter.\n",
    "@contextlib.contextmanager\n",
    "def assert_raises(error_class):\n",
    "    try:\n",
    "        yield\n",
    "    except error_class as e:\n",
    "        print('Caught expected exception \\n  {}:'.format(error_class))\n",
    "        traceback.print_exc(limit=2)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    else:\n",
    "        raise Exception('Expected {} to be raised but no error was raised!'.format(error_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPSfepzTHThq"
   },
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNwYTIJ8r56W"
   },
   "source": [
    "### Usage\n",
    "\n",
    "A `Function` you define (for example by applying the `@tf.function` decorator) is just like a core TensorFlow operation: You can execute it eagerly; you can compute gradients; and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SbtT1-Wm70F2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function  # The decorator converts `add` into a `Function`.\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "add(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uP-zUelB8DbX",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable(1.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    result = add(v, 1.0)\n",
    "tape.gradient(result, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocWZvqrmHnmX"
   },
   "source": [
    "You can use `Function`s inside other `Function`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "l5qRjdbBVdU6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def dense_layer(x, w, b):\n",
    "    return add(tf.matmul(x, w), b)\n",
    "\n",
    "dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piBhz7gYsHqU"
   },
   "source": [
    "`Function`s can be faster than eager code, especially for graphs with many small ops. But for graphs with a few expensive ops (like convolutions), you may not see much speedup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zuXt4wRysI03",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager conv: 0.8449165550118778\n",
      "Function conv: 0.7333571990020573\n",
      "Note how there's not much difference in performance for convolutions\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "conv_layer = tf.keras.layers.Conv2D(100, 3)\n",
    "\n",
    "@tf.function\n",
    "def conv_fn(image):\n",
    "    return conv_layer(image)\n",
    "\n",
    "image = tf.zeros([1, 200, 200, 100])\n",
    "\n",
    "# warm up\n",
    "conv_layer(image); conv_fn(image)\n",
    "print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\n",
    "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\n",
    "print(\"Note how there's not much difference in performance for convolutions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZ4Do2AV80cO"
   },
   "source": [
    "### Tracing\n",
    "\n",
    "This section exposes how `Function` works under the hood, including implementation details *which may change in the future*. However, once you understand why and when tracing happens, it's much easier to use `tf.function` effectively!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhpUtRqsXoyM"
   },
   "source": [
    "#### What is \"tracing\"?\n",
    "\n",
    "A `Function` runs your program in a [TensorFlow Graph](https://www.tensorflow.org/guide/intro_to_graphs#what_are_graphs). However, a `tf.Graph` cannot represent all the things that you'd write in an eager TensorFlow program. For instance, Python supports polymorphism, but `tf.Graph` requires its inputs to have a specified data type and dimension. Or you may perform side tasks like reading command-line arguments, raising an error, or working with a more complex Python object; none of these things can run in a `tf.Graph`.\n",
    "\n",
    "`Function` bridges this gap by separating your code in two stages:\n",
    "\n",
    "  1)  In the first stage, referred to as \"**tracing**\", `Function` creates a new `tf.Graph`. Python code runs normally, but all TensorFlow operations (like adding two Tensors) are *deferred*: they are captured by the `tf.Graph` and not run.\n",
    "\n",
    "  2) In the second stage, a `tf.Graph` which contains everything that was deferred in the first stage is run. This stage is much faster than the tracing stage.\n",
    "\n",
    "Depending on its inputs, `Function` will not always run the first stage when it is called.  See [\"Rules of tracing\"](#rules_of_tracing) below to get a better sense of how it makes that determination. Skipping the first stage and only executing the second stage is what gives you TensorFlow's high performance.\n",
    "\n",
    "When `Function` does decide to trace, the tracing stage is immediately followed by the second stage, so calling the `Function` both creates and runs the `tf.Graph`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7scSzLx662f"
   },
   "source": [
    "When we pass arguments of different types into a `Function`, both stages are run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kojmJrgq8U9v",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with Tensor(\"a:0\", shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "\n",
      "Tracing with Tensor(\"a:0\", shape=(), dtype=float32)\n",
      "tf.Tensor(2.2, shape=(), dtype=float32)\n",
      "\n",
      "Tracing with Tensor(\"a:0\", shape=(), dtype=string)\n",
      "tf.Tensor(b'aa', shape=(), dtype=string)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def my_func(a):\n",
    "    print(\"Tracing with\", a)\n",
    "    return a + a\n",
    "\n",
    "print(my_func(tf.constant(1))) # this will create a trace for tf.int32 tensor\n",
    "print()\n",
    "print(my_func(tf.constant(1.1))) # this will create a trace for tf.float32 tensor\n",
    "print()\n",
    "print(my_func(tf.constant(\"a\"))) # this will create a trace for tf.string tensor\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPfouGUQrcNb"
   },
   "source": [
    "Note that if you repeatedly call a `Function` with the same argument type, TensorFlow will skip the tracing stage and reuse a previously traced graph, as the generated graph would be identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "hFccbWFRrsBp",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'bb', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# This doesn't print 'Tracing with ...'\n",
    "print(my_func(tf.constant(\"b\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgIO_XEzcB9o"
   },
   "source": [
    "You can use `pretty_printed_concrete_signatures()` to see all of the available traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "IiQc4IKAb-NX",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_func(a)\n",
      "  Args:\n",
      "    a: float32 Tensor, shape=()\n",
      "  Returns:\n",
      "    float32 Tensor, shape=()\n",
      "\n",
      "my_func(a)\n",
      "  Args:\n",
      "    a: int32 Tensor, shape=()\n",
      "  Returns:\n",
      "    int32 Tensor, shape=()\n",
      "\n",
      "my_func(a)\n",
      "  Args:\n",
      "    a: string Tensor, shape=()\n",
      "  Returns:\n",
      "    string Tensor, shape=()\n"
     ]
    }
   ],
   "source": [
    "print(my_func.pretty_printed_concrete_signatures())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一些概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKQ92VEWI7n8"
   },
   "source": [
    "So far, you've seen that `tf.function` creates a cached, dynamic dispatch layer over TensorFlow's graph tracing logic. To be more specific about the terminology:\n",
    "\n",
    "- A `tf.Graph` is the raw, language-agnostic, portable representation of a TensorFlow computation.\n",
    "- A `ConcreteFunction` wraps a `tf.Graph`.\n",
    "- A `Function` manages a cache of `ConcreteFunction`s and picks the right one for your inputs，`Function` 和 `ConcreteFunction` 有点类似于泛型，Function 是没有指定类似的模版，ConcreteFunction 是指定类型后生成的模版函数\n",
    "- `tf.function` wraps a Python function, returning a `Function` object.\n",
    "- **Tracing** creates a `tf.Graph` and wraps it in a `ConcreteFunction`, also known as a **trace.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h62XoXho6EWN"
   },
   "source": [
    "#### Rules of tracing\n",
    "\n",
    "A `Function` determines whether to reuse a traced `ConcreteFunction` by computing a **cache key** from an input's args and kwargs. A **cache key** is a key that identifies a `ConcreteFunction` based on the input args and kwargs of the `Function` call, according to the following rules (which may change):\n",
    "\n",
    "- The key generated for a `tf.Tensor` is its shape and dtype.\n",
    "- The key generated for a `tf.Variable` is a unique variable id.\n",
    "- The key generated for a Python primitive (like `int`, `float`, `str`) is its value. \n",
    "- The key generated for nested `dict`s, `list`s, `tuple`s, `namedtuple`s, and [`attr`](https://www.attrs.org/en/stable/)s is the flattened tuple of leaf-keys (see `nest.flatten`).\n",
    "- For all other Python types, the keys are based on the object `id()` so that methods are traced independently for each instance of a class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNNN4lgRzpIs"
   },
   "source": [
    "Note: Cache keys are based on the `Function` input parameters so changes to global and free variables alone will not create a new trace. See [this section](#depending_on_python_global_and_free_variables) for recommended practices when dealing with Python global and free variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEDwbumO32Wh"
   },
   "source": [
    "#### Controlling retracing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUtycWJa34TT"
   },
   "source": [
    "Retracing, which is when your `Function` creates more than one trace, helps ensures that TensorFlow generates correct graphs for each set of inputs. However, tracing is an expensive operation! If your `Function` retraces a new graph for every call, you'll find that your code executes more slowly than if you didn't use `tf.function`.\n",
    "\n",
    "To control the tracing behavior, you can use the following techniques:\n",
    "\n",
    "- Specify `input_signature` in `tf.function` to limit tracing.\n",
    "- Cast Python arguments to Tensors to reduce retracing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用 input_signature 限制函数接受的参数类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_BDMIRmu1RGB",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with Tensor(\"x:0\", shape=(None,), dtype=int32)\n",
      "tf.Tensor([4 1], shape=(2,), dtype=int32)\n",
      "Caught expected exception \n",
      "  <class 'ValueError'>:\n",
      "Caught expected exception \n",
      "  <class 'ValueError'>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-af6dbe3f6b0e>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-8-f5f57cd00bde>\", line 10, in <module>\n",
      "    next_collatz(tf.constant([[1, 2], [3, 4]]))\n",
      "ValueError: Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-af6dbe3f6b0e>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-8-f5f57cd00bde>\", line 14, in <module>\n",
      "    next_collatz(tf.constant([1.0, 2.0]))\n",
      "ValueError: Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor([1. 2.], shape=(2,), dtype=float32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))\n",
    "def next_collatz(x):\n",
    "    print(\"Tracing with\", x)\n",
    "    return tf.where(x % 2 == 0, x // 2, 3 * x + 1)\n",
    "\n",
    "print(next_collatz(tf.constant([1, 2])))\n",
    "\n",
    "# We specified a 1-D tensor in the input signature, so this should fail.\n",
    "with assert_raises(ValueError):\n",
    "    next_collatz(tf.constant([[1, 2], [3, 4]]))\n",
    "\n",
    "# We specified an int32 dtype in the input signature, so this should fail.\n",
    "with assert_raises(ValueError):\n",
    "    next_collatz(tf.constant([1.0, 2.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 将 Python object 转换为 Tensorflow object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AY5oiQN0XIyA"
   },
   "source": [
    "Often, Python arguments are used to control hyperparameters and graph constructions - for example, `num_layers=10` or `training=True` or `nonlinearity='relu'`. So if the Python argument changes, it makes sense that you'd have to retrace the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AY5oiQN0XIyA"
   },
   "source": [
    "However, it's possible that a Python argument is not being used to control graph construction. In these cases, a change in the Python value can trigger needless retracing. Take, for example, this training loop, which AutoGraph will dynamically unroll. Despite the multiple traces, the generated graph is actually identical, so retracing is unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uydzR5JYUU8H",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retracing occurs for different Python arguments.\n",
      "Tracing with num_steps =  10\n",
      "Executing with num_steps =  10\n",
      "Tracing with num_steps =  20\n",
      "Executing with num_steps =  20\n",
      "\n",
      "Traces are reused for Tensor arguments.\n",
      "Tracing with num_steps =  Tensor(\"num_steps:0\", shape=(), dtype=int32)\n",
      "Executing with num_steps =  10\n",
      "Executing with num_steps =  20\n"
     ]
    }
   ],
   "source": [
    "def train_one_step():\n",
    "    pass\n",
    "\n",
    "@tf.function\n",
    "def train(num_steps):\n",
    "    print(\"Tracing with num_steps = \", num_steps)\n",
    "    tf.print(\"Executing with num_steps = \", num_steps)\n",
    "    for _ in tf.range(num_steps):\n",
    "        train_one_step()\n",
    "\n",
    "\n",
    "print(\"Retracing occurs for different Python arguments.\")\n",
    "train(num_steps=10)\n",
    "train(num_steps=20)\n",
    "\n",
    "print()\n",
    "print(\"Traces are reused for Tensor arguments.\")\n",
    "train(num_steps=tf.constant(10))\n",
    "train(num_steps=tf.constant(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96IxS2WR37fF"
   },
   "source": [
    "### Obtaining concrete functions\n",
    "\n",
    "Every time a function is traced, a new concrete function is created. You can directly obtain a concrete function, by using `get_concrete_function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "mHg2CGtPQ3Hz",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining concrete trace\n",
      "Executing traced function\n",
      "tf.Tensor(b'aa', shape=(), dtype=string)\n",
      "tf.Tensor(b'bb', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(\"Obtaining concrete trace\")\n",
    "double_strings = my_func.get_concrete_function(tf.constant(\"a\"))\n",
    "\n",
    "print(\"Executing traced function\")\n",
    "print(double_strings(tf.constant('a')))\n",
    "print(double_strings(tf.constant(\"b\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "6IVZ-NVf9vsx",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'cc', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# You can also call get_concrete_function on an InputSpec\n",
    "double_strings_from_inputspec = my_func.get_concrete_function(tf.TensorSpec(shape=[], dtype=tf.string))\n",
    "print(double_strings_from_inputspec(tf.constant(\"c\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iR4fVmG34xvF"
   },
   "source": [
    "Printing a `ConcreteFunction` displays a summary of its input arguments (with types) and its output type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "o3-JbkIk41r8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction my_func(a)\n",
      "  Args:\n",
      "    a: string Tensor, shape=()\n",
      "  Returns:\n",
      "    string Tensor, shape=()\n"
     ]
    }
   ],
   "source": [
    "print(double_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtqfvljZeuOV"
   },
   "source": [
    "You can also directly retrieve a concrete function's signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "nzbrqFABe0zG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((TensorSpec(shape=(), dtype=tf.string, name='a'),), {})\n",
      "Tensor(\"Identity:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(double_strings.structured_input_signature)\n",
    "print(double_strings.structured_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lar5A_5m5IG1"
   },
   "source": [
    "Using a concrete trace with incompatible types will throw an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "G5eeTK-T5KYj",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-30-af6dbe3f6b0e>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-53-6ba07b14b756>\", line 2, in <module>\n",
      "    double_strings(tf.constant(1))\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute __inference_my_func_478 as input #0(zero-based) was expected to be a string tensor but is a int32 tensor [Op:__inference_my_func_478]\n"
     ]
    }
   ],
   "source": [
    "with assert_raises(tf.errors.InvalidArgumentError):\n",
    "    double_strings(tf.constant(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "st2L9VNQVtSG"
   },
   "source": [
    "You may notice that Python arguments are given special treatment in a concrete function's input signature. Prior to TensorFlow 2.3, Python arguments were simply removed from the concrete function's signature. Starting with TensorFlow 2.3, Python arguments remain in the signature, but are constrained to take the value set during tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "U_QyPSGoaC35",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction pow(a, b=2)\n",
      "  Args:\n",
      "    a: float32 Tensor, shape=<unknown>\n",
      "  Returns:\n",
      "    float32 Tensor, shape=<unknown>\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def pow(a, b):\n",
    "  return a ** b\n",
    "\n",
    "square = pow.get_concrete_function(a=tf.TensorSpec(None, tf.float32), b=2)\n",
    "print(square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "E76vIDhQbXIb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'TypeError'>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1683, in _call_impl\n",
      "    cancellation_manager)\n",
      "  File \"/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1728, in _call_with_flat_signature\n",
      "    self._flat_signature_summary(), \", \".join(sorted(kwargs))))\n",
      "TypeError: pow(a) got unexpected keyword arguments: b.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-30-af6dbe3f6b0e>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-56-196bd40bd949>\", line 4, in <module>\n",
      "    square(tf.constant(10.0), b=3)\n",
      "TypeError: ConcreteFunction pow(a, b) was constructed with int value 2 in b, but was called with int value 3\n"
     ]
    }
   ],
   "source": [
    "assert square(tf.constant(10.0)) == 100\n",
    "\n",
    "with assert_raises(TypeError):\n",
    "    square(tf.constant(10.0), b=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41gJh_JGIfuA"
   },
   "source": [
    "### Obtaining graphs\n",
    "\n",
    "Each concrete function is a callable wrapper around a `tf.Graph`. Although retrieving the actual `tf.Graph` object is not something you'll normally need to do, you can obtain it easily from any concrete function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "5UENeGHfaX8g",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] -> a\n",
      "['a', 'a'] -> add\n",
      "['add'] -> Identity\n"
     ]
    }
   ],
   "source": [
    "graph = double_strings.graph\n",
    "for node in graph.as_graph_def().node:\n",
    "    print(f'{node.input} -> {node.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIKkgr6qdtp4"
   },
   "source": [
    "### How to Debug\n",
    "\n",
    "In general, debugging code is easier in eager mode than inside `tf.function`. You should ensure that your code executes error-free in eager mode before decorating with `tf.function`. To assist in the debugging process, you can call `tf.config.run_functions_eagerly(True)` to globally disable and reenable `tf.function`.\n",
    "\n",
    "When tracking down issues that only appear within `tf.function`, here are some tips:\n",
    "- Plain old Python `print` calls only execute during tracing, helping you track down when your function gets (re)traced.\n",
    "- `tf.print` calls will execute every time, and can help you track down intermediate values during execution.\n",
    "- `tf.debugging.enable_check_numerics` is an easy way to track down where NaNs and Inf are created.\n",
    "- `pdb` can help you understand what's going on during tracing. (Caveat: PDB will drop you into AutoGraph-transformed source code.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f05Vr_YBUCz"
   },
   "source": [
    "## AutoGraph Transformations\n",
    "\n",
    "AutoGraph is a library that is on by default in `tf.function`, and transforms a subset of Python eager code into graph-compatible TensorFlow ops. This includes control flow like `if`, `for`, `while`.\n",
    "\n",
    "TensorFlow ops like `tf.cond` and `tf.while_loop` continue to work, but control flow is often easier to write and understand when written in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "yCQTtTPTW3WF",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.648117423 0.200547457 0.858983517 0.445949674 0.367247343]\n",
      "[0.570401251 0.197901383 0.695733666 0.418563932 0.351581633]\n",
      "[0.515653908 0.195357621 0.601652801 0.395719945 0.337777466]\n",
      "[0.47433874 0.192909718 0.538224638 0.376280844 0.325491756]\n",
      "[0.441698253 0.190551803 0.491642922 0.359473228 0.314464122]\n",
      "[0.415051132 0.188278496 0.455519408 0.344749928 0.304492801]\n",
      "[0.392753124 0.186084837 0.426425368 0.331711322 0.295418739]\n",
      "[0.373731226 0.183966264 0.402329624 0.320057631 0.287114531]\n",
      "[0.357251018 0.181918606 0.381940514 0.309559017 0.279476881]\n",
      "[0.342790306 0.179937974 0.364391506 0.300035864 0.272420824]\n",
      "[0.329966187 0.17802082 0.349076271 0.291345417 0.265875965]\n",
      "[0.318490386 0.176163763 0.33555609 0.283372641 0.259783238]\n",
      "[0.308141291 0.174363762 0.323504299 0.276023626 0.254092753]\n",
      "[0.298745185 0.172617927 0.312672079 0.269220859 0.248762026]\n",
      "[0.290163845 0.170923606 0.302866 0.262899667 0.243754581]\n",
      "[0.282285601 0.169278309 0.293933213 0.257005662 0.239038929]\n",
      "[0.275019109 0.167679712 0.285750896 0.251492679 0.234587759]\n",
      "[0.26828891 0.166125655 0.278219223 0.246321261 0.230377182]\n",
      "[0.262031943 0.164614096 0.271256089 0.241457477 0.226386219]\n",
      "[0.256195068 0.163143128 0.264793247 0.236871928 0.222596407]\n",
      "[0.250733197 0.161710963 0.258773297 0.232538968 0.218991339]\n",
      "[0.245607749 0.160315931 0.253147751 0.228436202 0.215556458]\n",
      "[0.240785435 0.158956438 0.247875303 0.224543899 0.212278768]\n",
      "[0.236237466 0.157631025 0.242920369 0.220844612 0.209146589]\n",
      "[0.231938705 0.156338289 0.238252237 0.217322901 0.206149474]\n",
      "[0.227867186 0.155076891 0.233844221 0.213964984 0.20327796]\n",
      "[0.224003509 0.153845593 0.229673 0.210758507 0.200523511]\n",
      "[0.220330536 0.152643189 0.225718021 0.207692385 0.197878391]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([0.21683306, 0.1514686 , 0.2219612 , 0.20475668, 0.1953355 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple loop\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "    while tf.reduce_sum(x) > 1:\n",
    "        tf.print(x)\n",
    "        x = tf.tanh(x)\n",
    "    return x\n",
    "\n",
    "f(tf.random.uniform([5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxwJ8znPI0Cg"
   },
   "source": [
    "If you're curious you can inspect the code autograph generates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "jlQD1ffRXJhl",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__f(x):\n",
      "    with ag__.FunctionScope('f', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (x,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal x\n",
      "            (x,) = vars_\n",
      "\n",
      "        def loop_body():\n",
      "            nonlocal x\n",
      "            ag__.converted_call(ag__.ld(tf).print, (ag__.ld(x),), None, fscope)\n",
      "            x = ag__.converted_call(ag__.ld(tf).tanh, (ag__.ld(x),), None, fscope)\n",
      "\n",
      "        def loop_test():\n",
      "            return (ag__.converted_call(ag__.ld(tf).reduce_sum, (ag__.ld(x),), None, fscope) > 1)\n",
      "        ag__.while_stmt(loop_test, loop_body, get_state, set_state, ('x',), {})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(x)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tf.autograph.to_code(f.python_function))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgKmkrNTZSyz"
   },
   "source": [
    "### Conditionals\n",
    "\n",
    "AutoGraph will convert some `if <condition>` statements into the equivalent `tf.cond` calls. This substitution is made if `<condition>` is a Tensor. Otherwise, the `if` statement is executed as a Python conditional.\n",
    "\n",
    "A Python conditional executes during tracing, so exactly one branch of the conditional will be added to the graph. Without AutoGraph, this traced graph would be unable to take the alternate branch if there is data-dependent control flow.\n",
    "\n",
    "`tf.cond` traces and adds both branches of the conditional to the graph, dynamically selecting a branch at execution time. Tracing can have unintended side effects; see [AutoGraph tracing effects](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#effects-of-the-tracing-process) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "BOQl8PMq2Sf3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing for loop\n",
      "Tracing fizzbuzz branch\n",
      "Tracing fizz branch\n",
      "Tracing buzz branch\n",
      "Tracing default branch\n",
      "1\n",
      "2\n",
      "fizz\n",
      "3\n",
      "\n",
      "1\n",
      "2\n",
      "fizz\n",
      "3\n",
      "4\n",
      "buzz\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def fizzbuzz(n):\n",
    "    for i in tf.range(1, n + 1):\n",
    "        print('Tracing for loop')\n",
    "        if i % 15 == 0:\n",
    "            print('Tracing fizzbuzz branch')\n",
    "            tf.print('fizzbuzz')\n",
    "        elif i % 3 == 0:\n",
    "            print('Tracing fizz branch')\n",
    "            tf.print('fizz')\n",
    "        elif i % 5 == 0:\n",
    "            print('Tracing buzz branch')\n",
    "            tf.print('buzz')\n",
    "        else:\n",
    "            print('Tracing default branch')\n",
    "        tf.print(i)\n",
    "\n",
    "fizzbuzz(tf.constant(3))\n",
    "print()\n",
    "fizzbuzz(tf.constant(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yho4J0a0ZkQS"
   },
   "source": [
    "### Loops\n",
    "\n",
    "AutoGraph will convert some `for` and `while` statements into the equivalent TensorFlow looping ops, like `tf.while_loop`. If not converted, the `for` or `while` loop is executed as a Python loop.\n",
    "\n",
    "This substitution is made in the following situations:\n",
    "\n",
    "- `for x in y`: if `y` is a Tensor, convert to `tf.while_loop`. In the special case where `y` is a `tf.data.Dataset`, a combination of `tf.data.Dataset` ops are generated.\n",
    "- `while <condition>`: if `<condition>` is a Tensor, convert to `tf.while_loop`.\n",
    "\n",
    "A Python loop executes during tracing, adding additional ops to the `tf.Graph` for every iteration of the loop.\n",
    "\n",
    "A TensorFlow loop traces the body of the loop, and dynamically selects how many iterations to run at execution time.  The loop body only appears once in the generated `tf.Graph`.\n",
    "\n",
    "See the [reference documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#while-statements) for additional restrictions on AutoGraph-converted `for` and `while` statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义计算图中节点数的辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_graph_size(f, *args):\n",
    "  g = f.get_concrete_function(*args).graph\n",
    "  print(\"{}({}) contains {} nodes in its graph\".format(\n",
    "      f.__name__, ', '.join(map(str, args)), len(g.as_graph_def().node)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sp4rbIdfbM6s"
   },
   "source": [
    "#### Looping over Python data\n",
    "\n",
    "A common pitfall is to loop over Python/Numpy data within a `tf.function`. This loop will execute during the tracing process, adding a copy of your model to the `tf.Graph` for each iteration of the loop.\n",
    "\n",
    "If you want to wrap the entire training loop in `tf.function`, the safest way to do this is to wrap your data as a `tf.data.Dataset` so that AutoGraph will dynamically unroll the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WGZ19LspbZ27",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train([(1, 1), (1, 1), (1, 1)]) contains 11 nodes in its graph\n",
      "train([(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]) contains 32 nodes in its graph\n",
      "train(<FlatMapDataset shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>) contains 10 nodes in its graph\n",
      "train(<FlatMapDataset shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>) contains 10 nodes in its graph\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train(dataset):\n",
    "    loss = tf.constant(0)\n",
    "    for x, y in dataset:\n",
    "        loss += tf.abs(y - x)  # Some dummy computation.\n",
    "    return loss\n",
    "\n",
    "\n",
    "small_data = [(1, 1)] * 3\n",
    "big_data = [(1, 1)] * 10\n",
    "\n",
    "measure_graph_size(train, small_data)\n",
    "measure_graph_size(train, big_data)\n",
    "\n",
    "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
    "    lambda: small_data, (tf.int32, tf.int32)))\n",
    "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
    "    lambda: big_data, (tf.int32, tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeD2U-yrbfVb"
   },
   "source": [
    "When wrapping Python/Numpy data in a Dataset, be mindful of `tf.data.Dataset.from_generator` versus ` tf.data.Dataset.from_tensors`. The former will keep the data in Python and fetch it via `tf.py_function` which can have performance implications, whereas the latter will bundle a copy of the data as one large `tf.constant()` node in the graph, which can have memory implications.\n",
    "\n",
    "Reading data from files via TFRecordDataset/CsvDataset/etc. is the most effective way to consume data, as then TensorFlow itself can manage the asynchronous loading and prefetching of data, without having to involve Python. To learn more, see the [tf.data guide](../../guide/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 tf.range 代替 range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 range，会展开图，因此其中会有许多节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train(100) contains 200 nodes in its graph\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train(n):\n",
    "    for i in range(n):\n",
    "        tf.print(i)  \n",
    "        \n",
    "measure_graph_size(train, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而使用 tf.range，不会展开图，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train(100) contains 16 nodes in its graph\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train(n):\n",
    "    for i in tf.range(n):\n",
    "        tf.print(i)  \n",
    "\n",
    "measure_graph_size(train, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyksHW9TCukR"
   },
   "source": [
    "#### Use tf.TensorArray to accumulating values in a loop\n",
    "\n",
    "A common pattern is to accumulate intermediate values from a loop. Normally, this is accomplished by appending to a Python list or adding entries to a Python dictionary. However, as these are Python side effects, they will not work as expected in a dynamically unrolled loop. Use `tf.TensorArray` to accumulate results from a dynamically unrolled loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "HJ3Vb3dXfefN",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[0.94137156, 0.9822793 , 0.64925754, 0.2964362 ],\n",
       "        [0.99526787, 1.4181706 , 1.0210431 , 0.47227967],\n",
       "        [1.1410419 , 2.0621977 , 1.3571397 , 0.99516356]],\n",
       "\n",
       "       [[0.801937  , 0.52088714, 0.38815653, 0.54956937],\n",
       "        [1.7857704 , 0.87730646, 0.41332817, 0.8816924 ],\n",
       "        [2.5854597 , 1.5726612 , 0.8366827 , 1.3635818 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 3\n",
    "feature_size = 4\n",
    "\n",
    "\n",
    "def rnn_step(inp, state):\n",
    "    return inp + state\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def dynamic_rnn(rnn_step, input_data, initial_state):\n",
    "    # [batch, time, features] -> [time, batch, features]\n",
    "    input_data = tf.transpose(input_data, [1, 0, 2])\n",
    "    max_seq_len = input_data.shape[0]\n",
    "\n",
    "    states = tf.TensorArray(tf.float32, size=max_seq_len)\n",
    "    state = initial_state\n",
    "    for i in tf.range(max_seq_len):\n",
    "        state = rnn_step(input_data[i], state)\n",
    "        states = states.write(i, state)\n",
    "    return tf.transpose(states.stack(), [1, 0, 2])\n",
    "\n",
    "\n",
    "dynamic_rnn(rnn_step, tf.random.uniform([batch_size, seq_len, feature_size]),\n",
    "            tf.zeros([batch_size, feature_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2MVoIVaNApG"
   },
   "source": [
    "## Limitations\n",
    "\n",
    "TensorFlow `Function` has a few limitations by design that you should be aware of when converting a Python function to a `Function`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJqHGFSVLIKl"
   },
   "source": [
    "### Executing Python side effects\n",
    "\n",
    "Side effects, like printing, appending to lists, and mutating globals, can behave unexpectedly inside a `Function`, sometimes executing twice or not all. They only happen the first time you call a `Function` with a set of inputs.  Afterwards, the traced `tf.Graph` is reexecuted, without executing the Python code.\n",
    "\n",
    "The general rule of thumb is to avoid relying on Python side effects in your logic and only use them to debug your traces. Otherwise, TensorFlow APIs like `tf.data`, `tf.print`, `tf.summary`, `tf.Variable.assign`, and `tf.TensorArray` are the best way to ensure your code will be executed by the TensorFlow runtime with each call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T01:23:35.327204Z",
     "iopub.status.busy": "2021-03-19T01:23:35.326535Z",
     "iopub.status.idle": "2021-03-19T01:23:35.358573Z",
     "shell.execute_reply": "2021-03-19T01:23:35.358949Z"
    },
    "id": "w2sACuZ9TTRk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced with 1\n",
      "Executed with 1\n",
      "Executed with 1\n",
      "Traced with 2\n",
      "Executed with 2\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    print(\"Traced with\", x)\n",
    "    tf.print(\"Executed with\", x)\n",
    "\n",
    "f(1)\n",
    "f(1)\n",
    "f(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1I0dPiqTV8H"
   },
   "source": [
    "If you would like to execute Python code during each invocation of a `Function`, `tf.py_function` is an exit hatch. The drawback of `tf.py_function` is that it's not portable or particularly performant, cannot be saved with SavedModel, and does not work well in distributed (multi-GPU, TPU) setups. Also, since `tf.py_function` has to be wired into the graph, it casts all inputs/outputs to tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOW1v9WVKGgH"
   },
   "source": [
    "#### Changing Python global and free variables\n",
    "\n",
    "Changing Python global and free variables counts as a Python side effect, so it only happens during tracing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "7aJD--9qTWmg",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python side effect\n"
     ]
    }
   ],
   "source": [
    "external_list = []\n",
    "\n",
    "@tf.function\n",
    "def side_effect(x):\n",
    "    print('Python side effect') # only traced once\n",
    "    external_list.append(x) # only traced once\n",
    "\n",
    "side_effect(1)\n",
    "side_effect(1)\n",
    "# The list append only happened once!\n",
    "assert len(external_list) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbFG5CX4LwQA"
   },
   "source": [
    "You should avoid mutating containers like lists, dicts, other objects that live outside the `Function`. Instead, use arguments and TF objects. For example, the section [\"Accumulating values in a loop\"](#accumulating_values_in_a_loop) has one example of how list-like operations can be implemented.\n",
    "\n",
    "You can, in some cases, capture and manipulate state if it is a [`tf.Variable`](https://www.tensorflow.org/guide/variable). This is how the weights of Keras models are updated with repeated calls to the same `ConcreteFunction`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_oNNGrAqPJ1"
   },
   "source": [
    "#### Using Python iterators and generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msTmv-oyUNaf"
   },
   "source": [
    "Many Python features, such as generators and iterators, rely on the Python runtime to keep track of state. In general, while these constructs work as expected in eager mode, they are examples of Python side effects and therefore only happen during tracing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 对于 iterators 和 generators 属于 Python side effect，因此只 tracing 一次。m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "FNPD4unZUedH",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 1\n",
      "Value: 1\n",
      "Value: 1\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_consume_next(iterator):\n",
    "    tf.print(\"Value:\", next(iterator))\n",
    "\n",
    "iterator = iter([1, 2, 3])\n",
    "buggy_consume_next(iterator)\n",
    "\n",
    "# This reuses the first value from the iterator, rather than consuming the next value.\n",
    "buggy_consume_next(iterator)\n",
    "buggy_consume_next(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解决方法是用 tf.data.Iterator 来代替 python 的 iterators 或者 generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "8D_iKetXW6VE",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 1\n",
      "Value: 2\n",
      "Value: 3\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def good_consume_next(iterator):\n",
    "    # This is ok, iterator is a tf.data.Iterator\n",
    "    tf.print(\"Value:\", next(iterator))\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "iterator = iter(ds)\n",
    "good_consume_next(iterator)\n",
    "good_consume_next(iterator)\n",
    "good_consume_next(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHQ0UeU-vWo8"
   },
   "source": [
    "### Deleting tf.Variables between `Function` calls\n",
    "\n",
    "Another error you may encounter is a garbage-collected variable. `ConcreteFunction`s only retain [WeakRefs](https://docs.python.org/3/library/weakref.html) to the variables they close over, so you must retain a reference to any variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T01:23:35.460724Z",
     "iopub.status.busy": "2021-03-19T01:23:35.460152Z",
     "iopub.status.idle": "2021-03-19T01:23:35.496992Z",
     "shell.execute_reply": "2021-03-19T01:23:35.496383Z"
    },
    "id": "uMiRPfETjpt-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling concrete function...\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "\n",
      "Calling concrete function after garbage collecting its closed Variable...\n",
      "Caught expected exception \n",
      "  <class 'tensorflow.python.framework.errors_impl.FailedPreconditionError'>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-1-73d0ca52e838>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-1-9a93d2e07632>\", line 16, in <module>\n",
      "    traced_f(4)\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.\n",
      "  (0) Failed precondition:  Error while reading resource variable _AnonymousVar3 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar3/N10tensorflow3VarE does not exist.\n",
      "\t [[node ReadVariableOp (defined at <ipython-input-1-9a93d2e07632>:4) ]]\n",
      "  (1) Failed precondition:  Error while reading resource variable _AnonymousVar3 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar3/N10tensorflow3VarE does not exist.\n",
      "\t [[node ReadVariableOp (defined at <ipython-input-1-9a93d2e07632>:4) ]]\n",
      "\t [[ReadVariableOp/_2]]\n",
      "0 successful operations.\n",
      "0 derived errors ignored. [Op:__inference_f_782]\n",
      "\n",
      "Function call stack:\n",
      "f -> f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "external_var = tf.Variable(3)\n",
    "@tf.function\n",
    "def f(x):\n",
    "    return x * external_var\n",
    "\n",
    "\n",
    "traced_f = f.get_concrete_function(4)\n",
    "print(\"Calling concrete function...\")\n",
    "print(traced_f(4))\n",
    "\n",
    "# The original variable object gets garbage collected, since there are no more\n",
    "# references to it.\n",
    "external_var = tf.Variable(4)\n",
    "print()\n",
    "print(\"Calling concrete function after garbage collecting its closed Variable...\")\n",
    "with assert_raises(tf.errors.FailedPreconditionError):\n",
    "    traced_f(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-D6nh3QirXAd"
   },
   "source": [
    "## Known Issues\n",
    "\n",
    "If your `Function` is not evaluating correctly, the error may be explained by these known issues which are planned to be fixed in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close free variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "oeJMdXd3M0cM",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 8 calls to <function buggy_add at 0x16a0ef510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Buggy: tf.Tensor(2, shape=(), dtype=int32)\n",
      "Correct: tf.Tensor(2, shape=(), dtype=int32)\n",
      "\n",
      "Updating the value of `foo` to 2!\n",
      "Buggy: tf.Tensor(2, shape=(), dtype=int32)\n",
      "Correct: tf.Tensor(3, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_add():\n",
    "    return 1 + foo\n",
    "\n",
    "@tf.function\n",
    "def recommended_add(foo):\n",
    "    return 1 + foo\n",
    "\n",
    "foo = 1\n",
    "print(\"Buggy:\", buggy_add())\n",
    "print(\"Correct:\", recommended_add(foo))\n",
    "\n",
    "print()\n",
    "print(\"Updating the value of `foo` to 2!\")\n",
    "foo += 1\n",
    "print(\"Buggy:\", buggy_add())  # Did not change!\n",
    "print(\"Correct:\", recommended_add(foo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu0SnPwaL7pI"
   },
   "source": [
    "You can close over outer names, **as long as you don't update their values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果将上面的 foo 换成 tf.Variable，会怎么样呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function buggy_add at 0x16a43fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Buggy: tf.Tensor(1, shape=(), dtype=int32)\n",
      "Correct: tf.Tensor(1, shape=(), dtype=int32)\n",
      "\n",
      "Updating the value of `foo` to 2!\n",
      "Buggy: tf.Tensor(2, shape=(), dtype=int32)\n",
      "Correct: tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_add():\n",
    "    return 1 + foo\n",
    "\n",
    "@tf.function\n",
    "def recommended_add(foo):\n",
    "    return 1 + foo\n",
    "\n",
    "foo = tf.Variable(0)\n",
    "print(\"Buggy:\", buggy_add())\n",
    "print(\"Correct:\", recommended_add(foo))\n",
    "\n",
    "print()\n",
    "print(\"Updating the value of `foo` to 2!\")\n",
    "foo.assign_add(1) # 2\n",
    "print(\"Buggy:\", buggy_add())  # correct!\n",
    "print(\"Correct:\", recommended_add(foo)) # correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，结果是正确，因为在 tracing 的时候将 foo 这个节点也添加到 graph 中了，因此 foo 变化时，graph 仍然可以访问到 foom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是如果换成下面这种写法的话，会直接报错！这次我们用 foo = foo + 1 来更新 foo，和 foo.assign_add 不同，foo.assign_add 会原地修改 foo 的值，而 foo = foo + 1 会重新生成一个节点，因此 graph 无法找到原来的节点，所以会直接报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 12 calls to <function buggy_add at 0x16a440c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Buggy: tf.Tensor(1, shape=(), dtype=int32)\n",
      "Correct: tf.Tensor(1, shape=(), dtype=int32)\n",
      "\n",
      "Updating the value of `foo` to 2!\n",
      "Caught expected exception \n",
      "  <class 'Exception'>:\n",
      "Correct: tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-129-af6dbe3f6b0e>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-138-4c7ba1ed9810>\", line 17, in <module>\n",
      "    print(\"Buggy:\", buggy_add())  # Error!\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError:  Error while reading resource variable _AnonymousVar40 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar40/N10tensorflow3VarE does not exist.\n",
      "\t [[node ReadVariableOp (defined at <ipython-input-117-ac0e3fd57131>:3) ]] [Op:__inference_buggy_add_3299]\n",
      "\n",
      "Function call stack:\n",
      "buggy_add\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_add():\n",
    "    return 1 + foo\n",
    "\n",
    "@tf.function\n",
    "def recommended_add(foo):\n",
    "    return 1 + foo\n",
    "\n",
    "foo = tf.Variable(0)\n",
    "print(\"Buggy:\", buggy_add())\n",
    "print(\"Correct:\", recommended_add(foo))\n",
    "\n",
    "print()\n",
    "print(\"Updating the value of `foo` to 2!\")\n",
    "foo = foo + 1\n",
    "with assert_raises(Exception):\n",
    "    print(\"Buggy:\", buggy_add())  # Error!\n",
    "print(\"Correct:\", recommended_add(foo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvwe9gTIWfx6"
   },
   "source": [
    "#### Depending on Python objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJkZS-SwPvOQ"
   },
   "source": [
    "The recommendation to pass Python objects as arguments into `tf.function` has a number of known issues, that are expected to be fixed in the future. In general, you can rely on consistent tracing if you use a Python primitive or `tf.nest`-compatible structure as an argument or pass in a *different* instance of an object into a `Function`. However, `Function` will *not* create a new trace when you pass **the same object and only change its attributes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "ux8KJESVWDxX",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(20.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class SimpleModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        # These values are *not* tf.Variables.\n",
    "        self.bias = 0.\n",
    "        self.weight = 2.\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def evaluate(model, x):\n",
    "    return model.weight * x + model.bias\n",
    "\n",
    "\n",
    "simple_model = SimpleModel()\n",
    "x = tf.constant(10.)\n",
    "print(evaluate(simple_model, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "mUxRF4ghZZvX",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding bias!\n",
      "tf.Tensor(20.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding bias!\")\n",
    "simple_model.bias += 5.0\n",
    "print(evaluate(simple_model, x))  # Didn't change :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ytcgg2qFWaBF"
   },
   "source": [
    "Using the same `Function` to evaluate the updated instance of the model will be buggy since the updated model has the [same cache key](#rules_of_tracing) as the original model.\n",
    "\n",
    "For that reason, we recommend that you write your `Function` to avoid depending on mutable object attributes or create new objects.\n",
    "\n",
    "If that is not possible, one workaround is to make new `Function`s each time you modify your object to force retracing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "pFvWmWAAQjrv",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(20.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, x):\n",
    "    return model.weight * x + model.bias\n",
    "\n",
    "\n",
    "new_model = SimpleModel()\n",
    "evaluate_no_bias = tf.function(evaluate).get_concrete_function(new_model, x)\n",
    "# Don't pass in `new_model`, `Function` already captured its state during tracing.\n",
    "print(evaluate_no_bias(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "bdU2-jF4ZH0B",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding bias!\n",
      "tf.Tensor(25.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Adding bias!\")\n",
    "new_model.bias += 5.0\n",
    "# Create new Function and ConcreteFunction since you modified new_model.\n",
    "evaluate_with_bias = tf.function(evaluate).get_concrete_function(new_model, x)\n",
    "print(evaluate_with_bias(x)) # Don't pass in `new_model`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFgEZClsZrEi"
   },
   "source": [
    "As [retracing can be expensive](https://www.tensorflow.org/guide/intro_to_graphs#tracing_and_performance), you can use `tf.Variable`s as object attributes, which can be mutated (but not changed, careful!) for a similar effect without needing a retrace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T01:23:35.652984Z",
     "iopub.status.busy": "2021-03-19T01:23:35.652417Z",
     "iopub.status.idle": "2021-03-19T01:23:35.686446Z",
     "shell.execute_reply": "2021-03-19T01:23:35.685949Z"
    },
    "id": "daAP_lucwS6w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(20.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class BetterModel:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.bias = tf.Variable(0.)\n",
    "        self.weight = tf.Variable(2.)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def evaluate(model, x):\n",
    "    return model.weight * x + model.bias\n",
    "\n",
    "\n",
    "better_model = BetterModel()\n",
    "print(evaluate(better_model, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T01:23:35.690322Z",
     "iopub.status.busy": "2021-03-19T01:23:35.689680Z",
     "iopub.status.idle": "2021-03-19T01:23:35.692859Z",
     "shell.execute_reply": "2021-03-19T01:23:35.693207Z"
    },
    "id": "ktqwMJBqwTFj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding bias!\n",
      "tf.Tensor(25.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding bias!\")\n",
    "better_model.bias.assign_add(5.0)  # Note: instead of better_model.bias += 5\n",
    "print(evaluate(better_model, x))  # This works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPr_6mK_AQWL"
   },
   "source": [
    "### Creating tf.Variables\n",
    "\n",
    "`Function` only supports creating variables once, when first called, and then reusing them. You cannot create `tf.Variables` in new traces. Creating new variables in subsequent calls is currently not allowed, but will be in the future.\n",
    "\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T01:23:35.699557Z",
     "iopub.status.busy": "2021-03-19T01:23:35.697152Z",
     "iopub.status.idle": "2021-03-19T01:23:35.739056Z",
     "shell.execute_reply": "2021-03-19T01:23:35.739432Z"
    },
    "id": "Tx0Vvnb_9OB-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'ValueError'>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-1-73d0ca52e838>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-1-8a0913e250e0>\", line 7, in <module>\n",
      "    f(1.0)\n",
      "ValueError: in user code:\n",
      "\n",
      "    <ipython-input-1-8a0913e250e0>:3 f  *\n",
      "        v = tf.Variable(1.0)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/ops/variables.py:262 __call__  **\n",
      "        return cls._variable_v2_call(*args, **kwargs)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/ops/variables.py:256 _variable_v2_call\n",
      "        shape=shape)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/ops/variables.py:67 getter\n",
      "        return captured_getter(captured_previous, **kwargs)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py:731 invalid_creator_scope\n",
      "        \"tf.function-decorated function tried to create \"\n",
      "\n",
      "    ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    v = tf.Variable(1.0)\n",
    "    return v\n",
    "\n",
    "\n",
    "with assert_raises(ValueError):\n",
    "    f(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYm6-5GCILXQ"
   },
   "source": [
    "You can create variables inside a `Function` as long as those variables are only created the first time the function is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T01:23:35.774729Z",
     "iopub.status.busy": "2021-03-19T01:23:35.773722Z",
     "iopub.status.idle": "2021-03-19T01:23:35.805859Z",
     "shell.execute_reply": "2021-03-19T01:23:35.805331Z"
    },
    "id": "HQrG5_kOiKl_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "class Count(tf.Module):\n",
    "  def __init__(self):\n",
    "    self.count = None\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self):\n",
    "    if self.count is None:\n",
    "      self.count = tf.Variable(0)\n",
    "    return self.count.assign_add(1)\n",
    "\n",
    "c = Count()\n",
    "print(c())\n",
    "print(c())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uD6qI7aJwbR"
   },
   "source": [
    "#### Using with multiple Keras optimizers\n",
    "You may encounter `ValueError: tf.function-decorated function tried to create variables on non-first call.` when using more than one Keras optimizer with a `tf.function`. This error occurs because optimizers internally create `tf.Variables` when they apply gradients for the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-19T01:23:35.814376Z",
     "iopub.status.busy": "2021-03-19T01:23:35.811809Z",
     "iopub.status.idle": "2021-03-19T01:23:36.036597Z",
     "shell.execute_reply": "2021-03-19T01:23:36.037011Z"
    },
    "id": "yWQ3-r99Jvze"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling `train_step` with different optimizer...\n",
      "Caught expected exception \n",
      "  <class 'ValueError'>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-1-73d0ca52e838>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-1-d3d3937dbf1a>\", line 18, in <module>\n",
      "    train_step(w, x, y, opt2)\n",
      "ValueError: in user code:\n",
      "\n",
      "    <ipython-input-1-d3d3937dbf1a>:9 train_step  *\n",
      "        optimizer.apply_gradients(zip(gradients, [w]))\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:604 apply_gradients  **\n",
      "        self._create_all_weights(var_list)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:781 _create_all_weights\n",
      "        _ = self.iterations\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:788 __getattribute__\n",
      "        return super(OptimizerV2, self).__getattribute__(name)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:926 iterations\n",
      "        aggregation=tf_variables.VariableAggregation.ONLY_FIRST_REPLICA)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1132 add_weight\n",
      "        aggregation=aggregation)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py:810 _add_variable_with_custom_getter\n",
      "        **kwargs_for_getter)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer_utils.py:142 make_variable\n",
      "        shape=variable_shape if variable_shape else None)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/ops/variables.py:260 __call__\n",
      "        return cls._variable_v1_call(*args, **kwargs)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/ops/variables.py:221 _variable_v1_call\n",
      "        shape=shape)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/ops/variables.py:67 getter\n",
      "        return captured_getter(captured_previous, **kwargs)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py:731 invalid_creator_scope\n",
      "        \"tf.function-decorated function tried to create \"\n",
      "\n",
      "    ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt1 = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "opt2 = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(w, x, y, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        L = tf.reduce_sum(tf.square(w*x - y))\n",
    "    gradients = tape.gradient(L, [w])\n",
    "    optimizer.apply_gradients(zip(gradients, [w]))\n",
    "\n",
    "\n",
    "w = tf.Variable(2.)\n",
    "x = tf.constant([-1.])\n",
    "y = tf.constant([2.])\n",
    "\n",
    "train_step(w, x, y, opt1)\n",
    "print(\"Calling `train_step` with different optimizer...\")\n",
    "with assert_raises(ValueError):\n",
    "    train_step(w, x, y, opt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Q8BRPCThTjB"
   },
   "source": [
    "If you need to change the optimizer during training, a workaround is to create a new `Function` for each optimizer, calling the [`ConcreteFunction`](#obtaining_concrete_functions) directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "YV5F2Gy9hSI3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt1 = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "opt2 = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# Not a tf.function.\n",
    "\n",
    "\n",
    "def train_step(w, x, y, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        L = tf.reduce_sum(tf.square(w*x - y))\n",
    "    gradients = tape.gradient(L, [w])\n",
    "    optimizer.apply_gradients(zip(gradients, [w]))\n",
    "\n",
    "\n",
    "w = tf.Variable(2.)\n",
    "x = tf.constant([-1.])\n",
    "y = tf.constant([2.])\n",
    "\n",
    "# Make a new Function and ConcreteFunction for each optimizer.\n",
    "train_step_1 = tf.function(train_step).get_concrete_function(w, x, y, opt1)\n",
    "train_step_2 = tf.function(train_step).get_concrete_function(w, x, y, opt2)\n",
    "for i in range(10):\n",
    "    if i % 2 == 0:\n",
    "        train_step_1(w, x, y)  # `opt1` is not used as a parameter.\n",
    "    else:\n",
    "        train_step_2(w, x, y)  # `opt2` is not used as a parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xjnz5CcuqQac"
   },
   "source": [
    "#### Using with multiple Keras models\n",
    "\n",
    "You may also encounter `ValueError: tf.function-decorated function tried to create variables on non-first call.` when passing different model instances to the same `Function`.\n",
    "\n",
    "This error occurs because Keras models (which [do not have their input shape defined](https://www.tensorflow.org/guide/keras/custom_layers_and_models#best_practice_deferring_weight_creation_until_the_shape_of_the_inputs_is_known)) and Keras layers create `tf.Variables`s when they are first called. You may be attempting to initialize those variables inside a `Function`, which has already been called. To avoid this error, try calling `model.build(input_shape)` to initialize all the weights before training the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKyrEY5GVX3M"
   },
   "source": [
    "## Further reading\n",
    "\n",
    "To learn about how to export and load a `Function`, see the [SavedModel guide](../../guide/saved_model). To learn more about graph optimizations that are performed after tracing, see the [Grappler guide](../../guide/graph_optimization). To learn how to optimize your data pipeline and profile your model, see the [Profiler guide](../../guide/profiler.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- http://localhost:8888/lab/workspaces/auto-i/tree/DL-Project/learnTensorflow/Tensorflow2%20guide/function.ipynb#rules_of_tracing\n",
    "- [Better performance with tf.function  |  TensorFlow Core](https://www.tensorflow.org/guide/function)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "function.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2]",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
