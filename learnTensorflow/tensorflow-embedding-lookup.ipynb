{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[toc]\n",
    "\n",
    "# Tensorflow Embedding Lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding lookup 有两种理解方式，一种是将其理解为找到离散特征的嵌入表示。\n",
    "另一种理解是矩阵乘法在稀疏数据下的特殊情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 稀疏矩阵相乘的特殊情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:37:25.883086Z",
     "start_time": "2020-09-18T07:37:25.863964Z"
    }
   },
   "source": [
    "假设我们有一个稀疏矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:37:31.888492Z",
     "start_time": "2020-09-18T07:37:31.879224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=int32, numpy=\n",
       "array([[3],\n",
       "       [5],\n",
       "       [4]], dtype=int32)>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1, 0, 0], [0, 0, 1], [0, 1, 0]])\n",
    "w = tf.constant([[3], [4], [5]])\n",
    "tf.matmul(x, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:38:07.074401Z",
     "start_time": "2020-09-18T07:38:07.067305Z"
    }
   },
   "source": [
    "这个可以转化为 embedding_lookup 的情况。结果和矩阵乘法是相同的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:41:23.073297Z",
     "start_time": "2020-09-18T07:41:23.062924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=int32, numpy=\n",
       "array([[3],\n",
       "       [5],\n",
       "       [4]], dtype=int32)>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_x = tf.argmax(x)\n",
    "tf.nn.embedding_lookup(w, label_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一维情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设我们有一个权重矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:20:03.374130Z",
     "start_time": "2020-09-18T07:20:03.369047Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "embeddings = tf.constant([\n",
    "    [0.1, 0.1, 0.1, 0.1],\n",
    "    [0.2, 0.2, 0.2, 0.2],\n",
    "    [0.3, 0.3, 0.3, 0.3],\n",
    "    [0.4, 0.4, 0.4, 0.4],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的数据是包含两个样本和一个离散特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:29:19.775273Z",
     "start_time": "2020-09-18T07:29:19.771526Z"
    }
   },
   "outputs": [],
   "source": [
    "features = tf.constant([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:29:20.276826Z",
     "start_time": "2020-09-18T07:29:20.270586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[0.3, 0.3, 0.3, 0.3],\n",
       "       [0.4, 0.4, 0.4, 0.4]], dtype=float32)>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(embeddings, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding_lookup 相当于 one-hot 之后进行矩阵乘法，好处是不需要真的进行 one-hot 操作。因为 one-hot 出来的矩阵会占很多空间。\n",
    "\n",
    "也就是说，**`embedding_lookup` 可以看作一种针对特征情况的一种高效的矩阵乘法。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的 embedding_lookup 的过程相当于做了下面的矩阵乘法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:29:22.662676Z",
     "start_time": "2020-09-18T07:29:22.654430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]], shape=(2, 4), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[0.3, 0.3, 0.3, 0.3],\n",
       "       [0.4, 0.4, 0.4, 0.4]], dtype=float32)>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = tf.one_hot(features, depth=4)\n",
    "print(one_hot)\n",
    "tf.matmul(one_hot, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多维的情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还是上面的 embedding 矩阵，现在添加一个特征。离散特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:28:42.533923Z",
     "start_time": "2020-09-18T07:28:42.527119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 4), dtype=float32, numpy=\n",
       "array([[[0.3, 0.3, 0.3, 0.3],\n",
       "        [0.2, 0.2, 0.2, 0.2]],\n",
       "\n",
       "       [[0.4, 0.4, 0.4, 0.4],\n",
       "        [0.2, 0.2, 0.2, 0.2]]], dtype=float32)>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tf.constant([[2, 1],\n",
    "                        [3, 1]])\n",
    "\n",
    "tf.nn.embedding_lookup(embeddings, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:28:44.234402Z",
     "start_time": "2020-09-18T07:28:44.225728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0. 0. 1. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 1. 0. 0.]]], shape=(2, 2, 4), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 4), dtype=float32, numpy=\n",
       "array([[[0.3, 0.3, 0.3, 0.3],\n",
       "        [0.2, 0.2, 0.2, 0.2]],\n",
       "\n",
       "       [[0.4, 0.4, 0.4, 0.4],\n",
       "        [0.2, 0.2, 0.2, 0.2]]], dtype=float32)>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = tf.one_hot(features, depth=4)\n",
    "print(one_hot)\n",
    "tf.matmul(one_hot, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关于 embedding lookup 的研究"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method1 直接乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设我们有数据如下， 其中第一列是一个连续特征，后两列是离散特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:31:03.061718Z",
     "start_time": "2020-09-18T07:31:03.057466Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([\n",
    "                [0.1, 1, 0],\n",
    "                [0.2, 2, 1],\n",
    "                [0.3, 0, 2]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们一般是会对离散特征进行 one_hot，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:30:08.762352Z",
     "start_time": "2020-09-18T07:30:08.756412Z"
    }
   },
   "outputs": [],
   "source": [
    "sparse1 = tf.one_hot(tf.cast(x[:, 1], dtype=tf.int32), 3)\n",
    "sparse2 = tf.one_hot(tf.cast(x[:, 2], dtype=tf.int32), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:30:19.661969Z",
     "start_time": "2020-09-18T07:30:19.655525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.1 0.  1.  0.  1.  0.  0. ]\n",
      " [0.2 0.  0.  1.  0.  1.  0. ]\n",
      " [0.3 1.  0.  0.  0.  0.  1. ]], shape=(3, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "one_hot = tf.concat([x[:, :1], sparse1, sparse2], axis=1)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "权重矩阵为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:30:20.613175Z",
     "start_time": "2020-09-18T07:30:20.606986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [5.]\n",
      " [6.]\n",
      " [7.]], shape=(7, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w = tf.range(1, 8, dtype=tf.float32)[:, tf.newaxis]\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:31:07.985492Z",
     "start_time": "2020-09-18T07:31:07.979561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[ 8.1],\n",
       "       [10.2],\n",
       "       [ 9.3]], dtype=float32)>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(one_hot, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method2 embedding lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要使用 embedding_lookup，需要把所有的离散变量统一编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T06:55:22.418375Z",
     "start_time": "2020-09-18T06:55:22.407383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3],\n",
       "       [1, 4],\n",
       "       [2, 5]], dtype=int32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([\n",
    "                [0.1, 1, 0],\n",
    "                [0.2, 2, 1],\n",
    "                [0.3, 0, 2]]\n",
    ")\n",
    "\n",
    "x_sparse = x[:, 1:]\n",
    "idx = 0\n",
    "\n",
    "x_sparse_new = np.zeros_like(x_sparse, dtype=np.int32)\n",
    "val2idx = {}\n",
    "for j in range(2):\n",
    "    val2idx[j] = {}\n",
    "    for i in range(3):\n",
    "        val = x_sparse[i, j].numpy()\n",
    "        if val not in val2idx[j]:\n",
    "            val2idx[j][val] = idx\n",
    "            idx += 1  \n",
    "        x_sparse_new[i, j] = val2idx[j][val]\n",
    "        \n",
    "x_sparse_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时，对应的权重矩阵分别是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:00:10.998145Z",
     "start_time": "2020-09-18T07:00:10.993549Z"
    }
   },
   "outputs": [],
   "source": [
    "w_dense = tf.constant([[0.1], [0.2], [0.3]], dtype=tf.float32)\n",
    "w_sparse = tf.constant([[3], [4], [2], [5], [6], [7]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T07:00:11.734292Z",
     "start_time": "2020-09-18T07:00:11.728382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[ 8.1],\n",
       "       [10.2],\n",
       "       [ 9.3]], dtype=float32)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.nn.embedding_lookup(w_sparse, x_sparse_new), axis=1) + w_dense"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('tensorflow2': conda)",
   "language": "python",
   "name": "python361064bittensorflow2conda916f6dc8789a43e39b82205c8a731f83"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
