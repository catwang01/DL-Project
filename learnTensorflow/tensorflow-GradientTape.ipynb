{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Tensorflow GradientTape\n",
    "tags: 小书匠,Tensorflow,GradientTape\n",
    "grammar_cjkRuby: true\n",
    "# renderNumberedHeading: true\n",
    "---\n",
    "\n",
    "[toc!]\n",
    "\n",
    "# Tensorflow GradientTape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对于 tf.constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于 tf.constant 创建的变量，要计算，需要 watch；如果不 watch，计算出来的是 None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T15:56:37.383118Z",
     "start_time": "2020-07-27T15:56:34.452379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.constant(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x * x\n",
    "dx = tape.gradient(y, x)\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T15:56:40.345284Z",
     "start_time": "2020-07-27T15:56:40.336365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = x * x\n",
    "dx = tape.gradient(y, x)\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对于 tf.Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于 tf.Variable 创建出来的，会自动加入求导列表中，无需 watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T15:56:43.742076Z",
     "start_time": "2020-07-27T15:56:43.732813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x * x\n",
    "dx = tape.gradient(y, x)\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，待求导的变量除了初始化之外，所有参与的运算都要在 GradientTape 中才可以运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.Variable(3.0)\n",
    "x2 = x1 + 2\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x2 * x2\n",
    "dx = tape.gradient(y, x1)\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistent 参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认情况下，tape 只能用来计算一次导数。第二次计算导数会报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x * x\n",
    "dx = tape.gradient(y, x)\n",
    "new_dx = tape.gradient(y, x)\n",
    "print(dx)\n",
    "print(new_dx) # GradientTape.gradient can only be called once on non-persistent tapes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 `persistent=True` 可以让 tape 保持导数，可以多次计算。\n",
    "\n",
    "注意： 这时需要手动 GC。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    y = x * x\n",
    "dx = tape.gradient(y, x)\n",
    "new_dx = tape.gradient(y, x)\n",
    "print(dx) \n",
    "print(new_dx) # GradientTape.gradient can only be called once on non-persistent tapes.\n",
    "del tape # 手动gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多个 tape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于上面这种需要多次对不同的变量计算梯度的问题，除了使用 persistent 参数之外，还可以建立多个 GradientTape，如下面的[代码]([深度卷积生成对抗网络  |  TensorFlow Core](https://www.tensorflow.org/tutorials/generative/dcgan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "  generated_images = generator(noise, training=True)\n",
    "\n",
    "  real_output = discriminator(images, training=True)\n",
    "  fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "  gen_loss = generator_loss(fake_output)\n",
    "  disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算高阶导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as t1:\n",
    "    with tf.GradientTape() as t2:\n",
    "        y = x * x\n",
    "    dx = t2.gradient(y, x)\n",
    "ddx = t1.gradient(dx, x)\n",
    "\n",
    "print(dx) \n",
    "print(ddx) # GradientTape.gradient can only be called once on non-persistent tapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- http://localhost:8888/lab/tree/DL-Project/learnTensorflow/tensorflow-GradientTape.ipynb"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('srgan': conda)",
   "language": "python",
   "name": "python37664bitsrgancondad40efa82395a4251b23b581f920438c6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
