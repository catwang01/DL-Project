{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[toc]\n",
    "\n",
    "# Tensorflow tfrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 写入 tfrecord 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tars/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: This function is deprecated. Please call randint(0, 255 + 1) instead\n",
      "  if __name__ == '__main__':\n",
      "/opt/anaconda3/envs/tars/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tfrecords_filename = './train.tfrecords'\n",
    "writer = tf.python_io.TFRecordWriter(tfrecords_filename)  # 创建.tfrecord文件，准备写入\n",
    "\n",
    "for i in range(100):\n",
    "    # 模拟图像数据\n",
    "    img_raw = np.random.random_integers(0, 255,\n",
    "                                        size=(7, 30))  # 创建7*30，取值在0-255之间随机数组\n",
    "    img_raw = img_raw.tostring(\n",
    "    )  # array 类型的数据要转换为 string 然后用 tf.train.ByteList\n",
    "    features = tf.train.Features(\n",
    "        feature={\n",
    "            'label':\n",
    "            tf.train.Feature(int64_list=tf.train.Int64List(value=[i])),\n",
    "            'img_raw':\n",
    "            tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))\n",
    "        })\n",
    "    example = tf.train.Example(features=features)\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old 方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-41fa6119f57c>:2: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-2-41fa6119f57c>:3: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From <ipython-input-2-41fa6119f57c>:20: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "[[105  77  56 197 111 223  66 253 102 232  16  83 156 136  98 149  48 250\n",
      "    7 180 227  12  19 237 179 243 219  83 212   6]\n",
      " [ 14 232  10  23 197 215  81  24 134 243 172 187 151 224  86 166 225 233\n",
      "  102  95 121 178 157   2  98 131 255 168 234  71]\n",
      " [ 98  77 178  28 109  56  95   6 144  28  78  70  34   7 120  63 184  79\n",
      "  162  95 155 142 190 150  14 246 205 212  36 158]\n",
      " [161 112 112  98  66 240 181  62 222 168 240  68 250  90 121 187  33  11\n",
      "  218  11  86  98 142 185 102 214 182 125 120 162]\n",
      " [255 158  49 115 155  59 100 167  74 156 155 129 205 197 251 133  12 207\n",
      "  191 194 242  78 206  89  17  46 177 132 128 252]\n",
      " [ 74 194 228 180 151 220 171 120 234 201  84 251 183 137 203  68 185 245\n",
      "   19 219 102 237 153   8 107 189  16 246  90  51]\n",
      " [138 255 136 180   9  73 248  72  35  38 172 168 124 252 221  34 238 102\n",
      "    8 161 126  32 162  29  54  52   5 206 228 241]] 0\n",
      "[[195 161   0  44 157 184 101 134 122  53  71 143  88 253 113 157  60 147\n",
      "   81 124 252  99  94 156 104  80 125  38  64  83]\n",
      " [155  55   1 105 190 153 247 159  52 172 107 180 147 255  43 127 109 151\n",
      "  169  13  35 247 119 106 171 186 150 253  42  95]\n",
      " [251 127  81 121 144 106 237  49  65  42 118 231 108 123 100  17  68  66\n",
      "  172 116  18 128 189  46  50  36 122 255 145 120]\n",
      " [242  40  48  32 211  48  94 121 204 223  89  47 194  87 115  11 247  84\n",
      "  206 146 182  35 193 162  37 163 207  48  44 223]\n",
      " [  3 157 102 173 211 144 104 197 209 179 108 148   9 241  74 225 221  80\n",
      "  215 198 150 174  15   8 238 228  93   3  68  49]\n",
      " [186 196  69  55  83 148 205 196 115 137 227  77  33 222 187 223  11 198\n",
      "  125 102  68  87 143  40  92  23 112  81  81  67]\n",
      " [158   0 208   4 231  11 209 180  70 130 215   1 111 176 188 135 241  90\n",
      "  190 230 230 255 165 177 108  41 197  17  18 120]] 1\n",
      "[[109   6   8 245 234 155  41  58  30 247 247 140 216  96 142 252 231  93\n",
      "  110 147 164 152 244 237 102  84  81  20 186  20]\n",
      " [156 144 227  58 121   7 113 114 198  26  85 180 116 253  62 123 204 143\n",
      "  244 253 202 246  35 228 103 242  64  86 156  22]\n",
      " [ 21  92  68 180 146 134 192  21 238  33  57 108 139  28   3 156 175 165\n",
      "  232 160 215 222 135  12  75 200  50 168 155  33]\n",
      " [ 27 224 228 115  40 165 103 163  70 206 143  21 118 145  13 243 151 121\n",
      "  161 187 175  76  86 228 216  77  91 242  16   3]\n",
      " [113 251 122 139 187 162   4  81 197 190 227  78  49 235  25 148  87 126\n",
      "   41 120 199 154  74  12  93  95  97 184 128 221]\n",
      " [ 70 194 157  82   3   4  51  12  99   7  43 126  67  55  91  30 231  70\n",
      "  183 228  46 107 229   3  87  91 188  68  84  16]\n",
      " [240 212 189 101  95 199 216 241  82 114 200  10 238 209 164 190 239  12\n",
      "  155   9 254 191  32 142  32  80 146 134  88 115]] 2\n",
      "[[ 49 192 201 222  71   6 173  80  89 217 251 253 146  91   8 138  25 108\n",
      "  124  15 181 185 144 133 239  97  54  73 171 250]\n",
      " [169  25 142 240 203 171  16  37 142  95 199 205 133  47  42 106 119 157\n",
      "  199 189 136 239 191 181  46 109 224 144  81 164]\n",
      " [ 81  87 231  68 125  87 103 170  52  38 241  70  35 212 108  35  34 228\n",
      "  124  73 244 176 228  40 253 138 134 218 156 129]\n",
      " [  9 193 138 172 229 160  24 206 222 224  31  65 138 104  83  15 207 142\n",
      "  147 254   2  41  45 162 198 116 221 167 172  70]\n",
      " [ 90 155 130 172  34 251  40 132  70 213 160 217 159 246 137   2  78  29\n",
      "   30 138  45 180  32 228 111 220 190 162 242 119]\n",
      " [186  65 204 231   1 133 223 113 211 253 157  43  65  94  65 181 160  83\n",
      "  151 138   2 227  19 243 191 240 234 199  14 181]\n",
      " [147  33 137  14  63  75 220 234  20 163  75  97 184 193 237  47 156 202\n",
      "   68  48   8 183  38  72 119  13 137   9 143  83]] 3\n",
      "[[124 160  50  18  35 252 182  19 152  89 116 141 161  84  43 139 177  59\n",
      "  133 157  37 148 128 238 246  91  14 202 216  57]\n",
      " [202 186 165 214  41 130  23 187 108 176 229 161  34 182  97 107 101  62\n",
      "  135 178 123 203 206 247  74  32 250 252 114   1]\n",
      " [147  90 181 101 125  21  43 139 135  43  40  37  45 246  93  22 242  99\n",
      "  181 103 150 203 121 251 237 229 234  78  91  17]\n",
      " [175 101 209 197 217 103  98  39 176  96  71  18 200 167 201 233 115 204\n",
      "  140  91  29 127 185 236  84  93 202 129 196  43]\n",
      " [ 82 217  21 141  15 242  86 174  73  86 166  38  91 176 143 196 209   7\n",
      "  205  46 112 159 125  21 108  49  74 159  49  11]\n",
      " [ 73 205  86  22 155  96  77 139 164  42   6  31  71 163 103  52 154 253\n",
      "   45  38 189 143  50 149  91   6 152 151 200 247]\n",
      " [109 150 162 171  32 248  65 232 207  92  78   6 107 107  73 164 157  59\n",
      "  248 117 242 195 121  15 203 166 240 196  77  92]] 4\n"
     ]
    }
   ],
   "source": [
    "tfrecords_filename = \"train.tfrecords\"\n",
    "filename_queue = tf.train.string_input_producer([tfrecords_filename], )  #读入流中\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filename_queue)  #返回文件名和文件\n",
    "\n",
    "\n",
    "def _parse_record(example_photo):\n",
    "    features = {\n",
    "        'label': tf.FixedLenFeature([], tf.int64),\n",
    "        'img_raw': tf.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    parsed_features = tf.parse_single_example(\n",
    "        example_photo, features)  #取出包含image和label的feature对象\n",
    "    image = tf.decode_raw(parsed_features['img_raw'], tf.int64)\n",
    "    image = tf.reshape(image, [7, 30])\n",
    "    label = tf.cast(parsed_features['label'], tf.int64)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "image, label = _parse_record(serialized_example)\n",
    "with tf.Session() as sess:  #开始一个会话\n",
    "    coord = tf.train.Coordinator()  # 创建一个协调器，管理线程\n",
    "    threads = tf.train.start_queue_runners(\n",
    "        coord=coord)  # 启动QueueRunner, 此时文件名队列已经进队。\n",
    "    for i in range(3):\n",
    "        example, l = sess.run([image, label])  #在会话中取出image和label\n",
    "        print(example, l)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-ffb852186312>:23: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "(array([[212, 150, 186, 203, 231,  32, 159, 103, 216,  74, 255,  38,  64,\n",
      "        119,  20,  44, 100, 188, 212, 104,  43, 163,   5, 229,  43, 167,\n",
      "         85, 233, 191,  83],\n",
      "       [122, 230, 243,  24, 152,  86, 122, 234,  85, 227, 188, 125, 165,\n",
      "        160, 133, 129, 246, 145, 225, 214,  75, 110,  30, 133,  81, 181,\n",
      "         78,  24,  26, 123],\n",
      "       [ 90,  10, 150, 205,   8, 212, 167, 206,  62, 190, 145,  75, 139,\n",
      "        196,  34, 130, 148, 208, 118, 253, 194, 171, 217, 188,  91,  13,\n",
      "        117, 230, 191, 231],\n",
      "       [ 17,  63,  22,  50, 150, 251, 185, 112, 103, 210,  75, 195, 243,\n",
      "         11, 166, 209,  54, 122, 250,  18, 182, 221, 239, 236,   5, 212,\n",
      "         26, 167, 116,  94],\n",
      "       [165, 231, 252, 205,  19, 130,  70, 190, 250, 155,  31, 230, 102,\n",
      "         59,  91, 117, 209, 107,  95,  85, 184, 152, 244, 117, 195,  91,\n",
      "        123,  14,  69, 120],\n",
      "       [110,  77,  18,  63, 206,  56,   6,  22,  21, 235,  51,  57,  65,\n",
      "        234,  86, 137, 218, 200, 148, 207, 183,  27,  41,  31,  61, 122,\n",
      "        112, 238, 240,  77],\n",
      "       [161,  14, 240, 104, 239,  13, 243,  98,  24,  98, 222,   9, 131,\n",
      "         91,  88, 101, 120,  45,  66, 193, 180, 235, 224, 232,  88, 111,\n",
      "        170,  23, 181,  40]]), 0)\n",
      "(array([[176,  32,  75, 210, 229, 213, 243,  48, 243, 130, 223,  88, 111,\n",
      "        106, 203, 229,  56, 217,  26,  54, 202,  10, 229, 124,   3, 126,\n",
      "        220,  54,  51,  93],\n",
      "       [ 45, 173,  81, 140,  39,  51, 154,  28,  29, 234, 120, 196, 179,\n",
      "        125,  40,   3,   5, 159, 251,   9, 233, 163, 208, 151, 166, 194,\n",
      "        246, 208, 209,   4],\n",
      "       [ 65, 172,  96,  99,   1, 151,  89,  89, 119, 106,  33, 106,  70,\n",
      "        143, 252, 236, 205, 131, 188,  67,   4,  67, 121, 150, 237, 170,\n",
      "        161,   1,  13, 194],\n",
      "       [247,  89,  23, 218, 185,  98,   6,  28,   8, 118, 164, 198,  71,\n",
      "        104, 125, 198,  35, 164,  55,  90, 159, 174,  42,   3,  87, 216,\n",
      "         10, 120,  96, 207],\n",
      "       [149, 137,  83,  96, 242, 236, 215,  85, 132,  33, 117,  74,  59,\n",
      "          4, 166, 142, 211, 215, 250,  67,  70, 234, 251, 250,  17, 218,\n",
      "        251, 174, 198, 166],\n",
      "       [ 47, 176,  58, 172,  13,  80, 197,  19, 249,  54, 227, 127,  27,\n",
      "        173, 146,  77, 180, 137, 120,  90, 229, 166, 227, 200,  35,   6,\n",
      "         92, 119,  99, 219],\n",
      "       [177, 179,   0,  88, 128, 103, 182,  91, 131, 166, 212, 194,  47,\n",
      "          8,  26, 204, 221,  73,  28,   2,  78, 146, 156,  43, 227, 224,\n",
      "        129,  31, 199, 136]]), 1)\n",
      "(array([[192, 104,  31,  99, 170,  53,  95, 131, 253,   3, 201,  22, 108,\n",
      "        194,  80, 110, 185, 113,  99, 153,  99,  93, 153, 190, 109,  59,\n",
      "         75, 137, 212,  67],\n",
      "       [139,   1,  54,  90,  25, 198,  33,  83, 119, 129,  20,  78,  53,\n",
      "        223, 145, 177,  27, 178,  13, 210, 103, 101,  23,  31, 128, 150,\n",
      "        106,  47, 206, 205],\n",
      "       [ 63, 231, 231,  74,  91,  78,  93, 120,  51, 161, 100,  77, 183,\n",
      "        221,  78, 233, 222, 141,  70, 171, 193,  77, 124, 187,  87,  81,\n",
      "         61, 203,  99,  86],\n",
      "       [214, 101, 230, 180,  83,  41,  49, 195, 148, 229,  19, 221, 209,\n",
      "         42,  74, 186, 227,  13,  76, 204, 108,  59, 101, 235,  92, 120,\n",
      "        137, 225, 183, 202],\n",
      "       [163,  38,   1,  42, 198, 214, 199,  79, 242, 164, 246, 125,  16,\n",
      "        205, 174, 101, 153,  98,  90,  24, 227,  57, 145,  82, 166, 104,\n",
      "         20,  48, 158, 198],\n",
      "       [ 15, 117,  10, 170, 102,  68,  30, 113, 254,  72, 253,  55,  34,\n",
      "         66,  14, 118, 118,  53, 206, 154, 228,   4,  17, 246,  65, 210,\n",
      "        145, 193,   8,  22],\n",
      "       [140,  76, 113, 233, 190, 126,  34, 242,  17, 120, 254, 143, 130,\n",
      "         41, 171,  54, 148,   0,  76, 252, 130, 233,   6,  68, 164, 225,\n",
      "        126, 139,  91,  35]]), 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# _*_coding:utf-8_*_\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.reset_default_graph()\n",
    "\n",
    "input_file = \"train.tfrecords\"\n",
    "\n",
    "def _parse_record(example_photo):\n",
    "    features={\n",
    "       'label': tf.FixedLenFeature([], tf.int64),\n",
    "       'img_raw' : tf.FixedLenFeature([], tf.string),\n",
    "   }\n",
    "    parsed_features = tf.parse_single_example(example_photo, features)  #取出包含image和label的feature对象\n",
    "    image = tf.decode_raw(parsed_features['img_raw'], tf.int64)\n",
    "    image = tf.reshape(image, [7,30])\n",
    "    label = tf.cast(parsed_features['label'], tf.int64)\n",
    "    return image, label\n",
    "\n",
    "def read_test(input_file):\n",
    "    # 用dataset读取TFRecords文件\n",
    "    dataset = tf.data.TFRecordDataset(input_file)\n",
    "    dataset = dataset.map(_parse_record)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    next_batch = iterator.get_next() # 这个是一个数据，相当于 batchsize=1\n",
    "    return next_batch\n",
    "\n",
    "next_batch = read_test(input_file)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(3):\n",
    "        features = sess.run(next_batch)\n",
    "        print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 制作自己的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般我们使用 tfrecord 是结合 tf.estimator 或者 keras 来使用的，不需要我们自己读取。但是，有时我们还是会遇到需要自己从 tfrecord 中读取并喂入模型的情况。\n",
    "\n",
    "我们希望我们可以生成一个 `dataset`，然后用下面的形式遍历\n",
    "\n",
    "```py\n",
    "for batch in dataset:\n",
    "    output = model(batch)\n",
    "```\n",
    "\n",
    "利用 new method，我们可以制作自己的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 99"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.reset_default_graph()\n",
    "\n",
    "input_file = \"train.tfrecords\"\n",
    "\n",
    "def _parse_record(example_photo):\n",
    "    features={\n",
    "       'label': tf.FixedLenFeature([], tf.int64),\n",
    "       'img_raw' : tf.FixedLenFeature([], tf.string),\n",
    "   }\n",
    "    parsed_features = tf.parse_single_example(example_photo, features)  #取出包含image和label的feature对象\n",
    "    image = tf.decode_raw(parsed_features['img_raw'], tf.int64)\n",
    "    image = tf.reshape(image, [7,30])\n",
    "    label = tf.cast(parsed_features['label'], tf.int64)\n",
    "    return image, label\n",
    "\n",
    "def get_batch(input_file, sess):\n",
    "    # 用dataset读取TFRecords文件\n",
    "    dataset = tf.data.TFRecordDataset(input_file)\n",
    "    dataset = dataset.map(_parse_record)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    while True:\n",
    "        try:\n",
    "            data = sess.run(iterator.get_next())\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "        else:\n",
    "            yield data\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    i = 0\n",
    "    dataset = get_batch(input_file, sess) # dataset 是一个生成器\n",
    "    for image, label in dataset:\n",
    "        print(\"\\rbatch: {}\".format(i), end='')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 坑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. InvalidArgumentError: Key: my_key. Can't parse serialized Example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个主要是读取时的数据形状和写入时的不同导致的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': array([  101, 20662, 11444,  3326, 43267, 48626, 21334, 92425, 11325,\n",
      "        3025,  3025,   102,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0]), 'input_labels': array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0]), 'input_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "# _*_coding:utf-8_*_\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "max_seq_len = 40\n",
    "num_of_class = 10\n",
    "\n",
    "input_file = '/Users/bytedance/Git/devbox/data/test-data.tsv.tfrecord'\n",
    "def _parse_record(example_photo):\n",
    "    features = {\n",
    "        \"input_ids\":\n",
    "            tf.FixedLenFeature([max_seq_len], tf.int64),\n",
    "        \"input_mask\":\n",
    "            tf.FixedLenFeature([max_seq_len], tf.int64),\n",
    "        \"input_labels\":\n",
    "            tf.FixedLenFeature([num_of_class], tf.int64),\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.parse_single_example(example_photo, features=features)\n",
    "    return parsed_features\n",
    " \n",
    "def read_test(input_file):\n",
    "    # 用dataset读取TFRecords文件\n",
    "    dataset = tf.data.TFRecordDataset(input_file)\n",
    "    dataset = dataset.map(_parse_record)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator\n",
    "\n",
    "iterator = read_test(input_file)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    features = sess.run(iterator.get_next())\n",
    "    print(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. [tensorflow读取数据-tfrecord格式_几何君的算法天空-CSDN博客_tfrecord](https://blog.csdn.net/happyhorizion/article/details/77894055)\n",
    "2. [tensorflow TFRecords文件的生成和读取方法 - 知乎](https://zhuanlan.zhihu.com/p/31992460)\n",
    "3. [tensorflow学习笔记——高效读取数据的方法（TFRecord） - 战争热诚 - 博客园](https://www.cnblogs.com/wj-1314/p/11211333.html)\n",
    "\n",
    "4.  [TFRecord文件查看包含的所有Features_海涛技术漫谈-CSDN博客](https://blog.csdn.net/zhanht/article/details/100177528)\n",
    "\n",
    "5. [python - Tensorflow TFRecord: Can't parse serialized example - Stack Overflow](https://stackoverflow.com/questions/53499409/tensorflow-tfrecord-cant-parse-serialized-example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tars]",
   "language": "python",
   "name": "conda-env-tars-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
