{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[toc]\n",
    "\n",
    "# Tensorflow Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(features, feature_columns, hiddens, output_dim):\n",
    "    inputs = tf.feature_column.input_layer(features=features, feature_columns=feature_columns)\n",
    "\n",
    "    for hidden_unit in hiddens:\n",
    "        inputs = tf.layers.dense(inputs=inputs, units=hidden_unit, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=inputs, units=output_dim)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型层是一个函数，返回一个 `tf.estimator.EstimatorSpec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(lr):\n",
    "    \n",
    "    def model_fn(features, labels, mode, params, config):\n",
    "        logits = create_model(features, params['feature_columns'], params['hiddens'], params['output_dim'])\n",
    "        predict_pro  = tf.nn.softmax(logits)\n",
    "        predict_cls = tf.argmax(logits, axis=1)\n",
    "        if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "            loss = tf.losses.sparse_softmax_cross_entropy(labels=labels,logits=logits)\n",
    "        print(mode)\n",
    "        def get_metric(labels, predictions):\n",
    "            '''\n",
    "            define metrics\n",
    "            '''\n",
    "            accuracy = tf.metrics.accuracy(labels=labels, \n",
    "                                           predictions=predictions, \n",
    "                                           name='iris_accuracy')\n",
    "            recall = tf.metrics.recall(labels=labels,\n",
    "                                       predictions=predictions,\n",
    "                                       name='iris_recall')\n",
    "            precision, precision_update=tf.metrics.precision(labels=labels,predictions=predictions,name='iris_precision')\n",
    "            \n",
    "            return {\n",
    "                'accuracy':accuracy,\n",
    "                'recall': recall,\n",
    "                'precision':(precision,precision_update)                  \n",
    "            }\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            train_op = tf.train.AdamOptimizer(lr).minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                              loss=loss,\n",
    "                                              train_op=train_op,\n",
    "                                              eval_metric_ops=get_metric(labels,predict_cls))\n",
    "        \n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                              loss=loss,\n",
    "                                              eval_metric_ops=get_metric(labels,predict_cls))\n",
    "        \n",
    "        elif mode == tf.estimator.ModeKeys.PREDICT or mode == tf.estimator.ModeKeys.INFER:\n",
    "            predictions={'predict_cls':predict_cls,\n",
    "                         'predict_pro':predict_pro}\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                              predictions=predictions)  \n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path: /Users/bytedance/.keras/datasets/./data\n",
      "test_path: /Users/bytedance/.keras/datasets/./data\n"
     ]
    }
   ],
   "source": [
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "def downloadfiles():\n",
    "    train_path = tf.keras.utils.get_file(fname=r'./data', origin=TRAIN_URL)\n",
    "    test_path = tf.keras.utils.get_file(fname=r'./data', origin=TEST_URL)\n",
    "    return train_path, test_path\n",
    "\n",
    "train_path,test_path = downloadfiles()\n",
    "print(\"train_path: {}\\ntest_path: {}\".format(train_path, test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 400\n",
    "STEPS = 40\n",
    "LR = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义输入层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出层是一个函数，返回 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_TYPES=[[0.0], [0.0], [0.0], [0.0], [0]]\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'label']\n",
    "label = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "def input_fn_builder(file_path, epochs, batch_size, istrain=False):\n",
    "    \n",
    "    def parse_line(line): # 这个给 map 函数用来解析行\n",
    "        '''\n",
    "        parse csv line to features fromat\n",
    "        '''\n",
    "        fileds = tf.decode_csv(line,record_defaults=CSV_TYPES)\n",
    "        features = dict(zip(CSV_COLUMN_NAMES,fileds))\n",
    "        label = features.pop('label')\n",
    "        return features,label\n",
    "    \n",
    "    def input_fn():\n",
    "        dataset = tf.data.TextLineDataset(file_path).skip(1)\n",
    "        dataset = dataset.map(parse_line)\n",
    "        if istrain:\n",
    "            dataset = dataset.shuffle(1000)\n",
    "        dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "        return dataset # 返回的 顺序要和 model_fn一致 或者 dataset元素 格式为（features,label）元组 也可以\n",
    "    \n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = r'./model'\n",
    "params = {}\n",
    "feature_columns = []\n",
    "for i in range(len(CSV_COLUMN_NAMES)-1):\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(CSV_COLUMN_NAMES[i])\n",
    "    )\n",
    "params['feature_columns'] = feature_columns\n",
    "params['hiddens'] = [128, 256, 256]\n",
    "params['output_dim'] = len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff789f2b650>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "config = tf.estimator.RunConfig(save_checkpoints_steps=100)\n",
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn_builder(LR), # 这里需要一个函数\n",
    "    model_dir=model_dir, \n",
    "    params=params,\n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column.py:206: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column.py:2158: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column.py:207: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-184dad39fb8d>:5: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2200: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-40\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 40 into ./model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.7839321, step = 41\n",
      "INFO:tensorflow:Saving checkpoints for 80 into ./model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.68709654.\n"
     ]
    }
   ],
   "source": [
    "train = estimator.train(input_fn=input_fn_builder(file_path=train_path,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    epochs=EPOCHS), # 这里也需要一个函数\n",
    "                        steps=STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-01-26T18:39:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-80\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [4/40]\n",
      "INFO:tensorflow:Evaluation [8/40]\n",
      "INFO:tensorflow:Evaluation [12/40]\n",
      "INFO:tensorflow:Evaluation [16/40]\n",
      "INFO:tensorflow:Evaluation [20/40]\n",
      "INFO:tensorflow:Evaluation [24/40]\n",
      "INFO:tensorflow:Evaluation [28/40]\n",
      "INFO:tensorflow:Evaluation [32/40]\n",
      "INFO:tensorflow:Evaluation [36/40]\n",
      "INFO:tensorflow:Evaluation [40/40]\n",
      "INFO:tensorflow:Finished evaluation at 2021-01-26-18:39:14\n",
      "INFO:tensorflow:Saving dict for global step 80: accuracy = 0.7109375, global_step = 80, loss = 0.60199016, precision = 1.0, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 80: ./model/model.ckpt-80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7109375,\n",
       " 'loss': 0.60199016,\n",
       " 'precision': 1.0,\n",
       " 'recall': 1.0,\n",
       " 'global_step': 80}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate(  input_fn,    steps=None,    hooks=None,    checkpoint_path=None,    name=None)\n",
    "estimator.evaluate(input_fn=input_fn_builder(file_path=test_path,\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            epochs=EPOCHS), steps=STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x7ff7999ac750>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict(    input_fn,    predict_keys=None,    hooks=None,    checkpoint_path=None,    yield_single_examples=True)\n",
    "estimator.predict(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow 使用 pb 模型格式作为 serving 的模型。而 train 和 test 还都是 checkpoint 格式的数据，需要将我们 train 出来的 checkpoint 格式的数据转换为 pb 格式的数据。\n",
    "\n",
    "`tf.estimator` 提供了 `tf.estimator.export_savedmodel` 这个函数来实现上面的功能，它做了下面的几件事\n",
    "\n",
    "1. 增加placeholders到graph中，serving系统在获得inference请求时会进行feed数据\n",
    "\n",
    "2. 增加了额外ops：可以将原有输入格式的数据转换成模型所需特征tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 serving 层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.estimator.export.ServingInputReceiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    input_str = tf.placeholder(tf.string,name='inputs')\n",
    "    \n",
    "    # 在这里的处理方式，根据输入的不同，处理方式 会不同，我这里只是demo\n",
    "    line = tf.string_split(input_str,',').values \n",
    "    features = {\n",
    "      'SepalLength': tf.string_to_number([line[0]], tf.float32),\n",
    "      'SepalWidth': tf.string_to_number([line[1]], tf.float32),\n",
    "      'PetalLength':  tf.string_to_number([line[2]], tf.float32),\n",
    "      'PetalWidth': tf.string_to_number([line[3]], tf.float32)\n",
    "    }   \n",
    "    \n",
    "    receiver_tensors = {'inputs': input_str}\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的例子中，有 receiver_tensors 和 features，其中 reciever_tensors 是我们的输入，而 reciever_tensors 是模型的输入。 `serving_input_receiver_fn` 的第二个作用就是编写将 receiver_tensors 变成 features 的逻辑。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.estimator.export.build_raw_serving_input_receiver_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们的输入不需要经过处理，那么可以简单的使用 `tf.estimator.export.build_raw_serving_input_receiver_fn` 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_serving_input_fn():\n",
    "    SepalLength = tf.placeholder(tf.float32, [None], name='SepalLength')\n",
    "    SepalWidth = tf.placeholder(tf.float32, [None], name='SepalWidth')\n",
    "    PetalLength = tf.placeholder(tf.float32, [None], name='PetalLength')\n",
    "    PetalWidth = tf.placeholder(tf.float32, [None], name='PetalWidth')\n",
    "    input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
    "        'SepalLength': SepalLength,\n",
    "        'SepalWidth': SepalWidth,\n",
    "        'PetalLength': PetalLength,\n",
    "        'PetalWidth': PetalWidth,\n",
    "    })()\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "infer\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-80\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: export_base/iris/temp-b'1611673453'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'export_base/iris/1611673453'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.export_savedmodel('export_base/iris', serving_input_receiver_fn=raw_serving_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，export_base/iris 目录下多了一个 1611673453 目录，这个目录中存放这 pb 文件和 variables 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mexport_base/iris\u001b[00m\r\n",
      "└── \u001b[01;34m1611673453\u001b[00m\r\n",
      "    ├── saved_model.pb\r\n",
      "    └── \u001b[01;34mvariables\u001b[00m\r\n",
      "        ├── variables.data-00000-of-00001\r\n",
      "        └── variables.index\r\n",
      "\r\n",
      "2 directories, 3 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree export_base/iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 saved_model_cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['PetalLength'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: PetalLength_1:0\n",
      "    inputs['PetalWidth'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: PetalWidth_1:0\n",
      "    inputs['SepalLength'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: SepalLength_1:0\n",
      "    inputs['SepalWidth'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: SepalWidth_1:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['predict_cls'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1)\n",
      "        name: ArgMax:0\n",
      "    outputs['predict_pro'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 3)\n",
      "        name: Softmax:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir export_base/iris/1611673453 --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 saved_model_cli 还可以用一组输入进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-26 23:06:52.487617: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2021-01-26 23:06:52.499550: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa801fbb830 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-01-26 23:06:52.499577: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/tools/saved_model_cli.py:420: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "Result for output key predict_cls:\n",
      "[0 2 2]\n",
      "Result for output key predict_pro:\n",
      "[[0.66284543 0.18443526 0.15271927]\n",
      " [0.17048366 0.37887084 0.45064554]\n",
      " [0.08769966 0.36253315 0.54976714]]\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli run --dir export_base/iris/1611673453 \\\n",
    "    --tag_set serve \\\n",
    "    --signature_def \"serving_default\" \\\n",
    "    --input_expr 'SepalLength=[5.1,5.9,6.9];SepalWidth=[3.3,3.0,3.1];PetalLength=[1.7,4.2,5.4];PetalWidth=[0.5,1.5,2.1]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_cli run --dir intent_model_correct-1.savedmodel/1611676053 \\\n",
    "    --tag_set serve \\\n",
    "    --signature_def \"serving_default\" \\\n",
    "    --input_expr 'input_ids=[[1,2,3,4,5,6,7,8,9,10]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-fd5f86d07d1f>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-fd5f86d07d1f>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    self.finish(....)\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model_path = 'export_base/iris/1608121703'\n",
    "# 2. 使用 tornado/flask\n",
    "# steps：\n",
    "# 1. load model\n",
    "predictor = tf.contrib.predictor.from_saved_model(model_path) # model_path必须指定具体的版本号\n",
    "\n",
    "# 2. predict\n",
    "predict_result = predictor(input_params) # input_params 格式必须 符合 serving_input_receiver_fn中入参\n",
    "                                        #     predict_result 格式和 model_fn中返回格式一致\n",
    "# 3. using tornado\n",
    "class b_vxHandler(tornado.web.RequestHandler): \n",
    "\n",
    "    def post(self, version):\n",
    "        try:\n",
    "            predict_result = predictor(input_params)\n",
    "        except BaseException as err:\n",
    "            self.finish(....)\n",
    "\n",
    "\n",
    "application = tornado.web.Application([\n",
    "    (r\"/b/(?P<version>v\\d+)\", b_vxHandler),\n",
    "])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # tornado.options.parse_command_line()\n",
    "    application.listen(options.port)\n",
    "    tornado.ioloop.IOLoop.instance().start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. [《Estimator工程实现》系列三： SavedModel模型保存导出示例 - 简书](https://www.jianshu.com/p/72058da4d7f7)\n",
    "\n",
    "2. [tensorflow中模型的保存与使用总结 — carlos9310](https://carlos9310.github.io/2019/10/13/tensorflow-model-save-use/#run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tars]",
   "language": "python",
   "name": "conda-env-tars-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
