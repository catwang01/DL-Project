{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[toc]\n",
    "\n",
    "# Tensorflow Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path: /Users/bytedance/.keras/datasets/./data\n",
      "test_path: /Users/bytedance/.keras/datasets/./data\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "\n",
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "def downloadfiles():\n",
    "    train_path = tf.keras.utils.get_file(fname=r'./data', origin=TRAIN_URL)\n",
    "    test_path = tf.keras.utils.get_file(fname=r'./data', origin=TEST_URL)\n",
    "    return train_path, test_path\n",
    "\n",
    "train_path,test_path = downloadfiles()\n",
    "print(\"train_path: {}\\ntest_path: {}\".format(train_path, test_path))\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 400\n",
    "STEPS = 40\n",
    "LR = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的主要部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(features, feature_columns, hiddens, output_dim):\n",
    "    inputs = tf.feature_column.input_layer(features=features, feature_columns=feature_columns)\n",
    "\n",
    "    for hidden_unit in hiddens:\n",
    "        inputs = tf.layers.dense(inputs=inputs, units=hidden_unit, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=inputs, units=output_dim)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "光有模型的主要部分还不够，我们常常希望我们的模型可以在不同情况下输出不同的值。比如\n",
    "\n",
    "- 如果我们在训练阶段，那么我们希望模型输出 loss 和 train_op\n",
    "- 如果我们在测试阶段，那么我们希望模型可以输出一些指标，如 acc、precision、recall\n",
    "- 如果我们在预测阶段，那么我们希望模型可以直接输出预测结果。\n",
    "\n",
    "这就需要我们通过模型层，根据不同的 mode 来改变我们模型的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ee723668dc7b29f293d05ee10e3e3feb.png](evernotecid://17DACF27-DD15-47AE-A79A-0E370E882109/appyinxiangcom/22483756/ENResource/p13198)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型层是一个回调函数，它接受一堆参数，并返回一个 `tf.estimator.EstimatorSpec`\n",
    "\n",
    "我们的模型会根据不同的 mode 来转换不同的输出。这个是通过判断 mode 来返回不同的 `tf.estimator.EstimatorSpec` 来实现的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.estimator.EstimatorSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 原型\n",
    "\n",
    "它是一个class(类)，是定义在model\\_fn中的，并且model\\_fn返回的也是它的一个实例，这个实例是用来初始化Estimator类的。其源代码如下:\n",
    "\n",
    "```\n",
    "class EstimatorSpec():\n",
    "  def __new__(cls,\n",
    "              mode,\n",
    "              predictions=None,\n",
    "              loss=None,\n",
    "              train_op=None,\n",
    "              eval_metric_ops=None,\n",
    "              export_outputs=None,\n",
    "              training_chief_hooks=None,\n",
    "              training_hooks=None,\n",
    "              scaffold=None,\n",
    "              evaluation_hooks=None,\n",
    "              prediction_hooks=None):\n",
    "```\n",
    "\n",
    "重要函数参数：\n",
    "\n",
    "*   mode：一个ModeKeys,指定是training(训练)、evaluation(计算)还是prediction(预测).\n",
    "*   predictions：Predictions `Tensor` or dict of `Tensor`.\n",
    "*   loss：Training loss `Tensor`. Must be either scalar, or with shape `[1]`.\n",
    "*   train\\_op：适用于训练的步骤.\n",
    "*   eval\\_metric\\_ops: Dict of metric results keyed by name.\n",
    "    The values of the dict can be one of the following:\n",
    "    *   (1) instance of `Metric` class.\n",
    "    *   (2) Results of calling a metric function, namely a `(metric_tensor, update_op)` tuple. `metric_tensor` should be evaluated without any impact on state (typically is a pure computation results based on variables.). For example, it should not trigger the `update_op` or requires any input fetching.\n",
    "\n",
    "其他参数的作用可参见[源代码](https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/model_fn.py)说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 不同模式需要传入不同参数\n",
    "\n",
    "根据mode的值的不同,需要不同的参数,即：\n",
    "\n",
    "*   对于mode == ModeKeys.TRAIN：必填字段是 loss 和 train_op.\n",
    "*   对于mode == ModeKeys.EVAL：必填字段是 loss.\n",
    "*   对于mode == ModeKeys.PREDICT：必填字段是predictions.\n",
    "\n",
    "上面的参数说明看起来还是一头雾水，下面给出例子帮助理解："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 最简单的情况： predict\n",
    "\n",
    "只需要传入`mode`和`predictions`\n",
    "\n",
    "```\n",
    "# Compute predictions.\n",
    "predicted_classes = tf.argmax(logits, 1)\n",
    "if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    predictions = {\n",
    "        'class_ids': predicted_classes[:, tf.newaxis],\n",
    "        'probabilities': tf.nn.softmax(logits),\n",
    "        'logits': logits,\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "```\n",
    "\n",
    "##### 评估模式：eval\n",
    "\n",
    "需要传入`mode`,`loss`,`eval_metric_ops`\n",
    "\n",
    "如果调用 Estimator 的 evaluate 方法，则 `model_fn` 会收到 mode = ModeKeys.EVAL。在这种情况下，模型函数必须返回一个包含模型损失和一个或多个指标（可选）的 tf.estimator.EstimatorSpec。\n",
    "\n",
    "\n",
    "返回方式如下：\n",
    "\n",
    "```\n",
    "# Compute loss.\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "metrics = {'accuracy': accuracy}\n",
    "# Compute evaluation metrics.\n",
    "accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                               predictions=predicted_classes,\n",
    "                               name='acc_op')\n",
    "\n",
    "if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 训练模式：train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要传入`mode`,`loss`,`train_op`\n",
    "\n",
    "loss同eval模式：\n",
    "\n",
    "```\n",
    "if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "    train_op = optimizer.minimize(loss,global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 通用模式\n",
    "\n",
    "`model_fn` 可以还可以填充独立于模式的所有参数.在这种情况下,Estimator将忽略某些参数.在eval和infer模式中, `train_op` 将被忽略.例子如下：\n",
    "\n",
    "```\n",
    "def my_model_fn(mode, features, labels):\n",
    "  predictions = ...\n",
    "  loss = ...\n",
    "  train_op = ...\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=predictions,\n",
    "      loss=loss,\n",
    "      train_op=train_op)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(lr): # 这个只是利用来传递参数 lr，真正的部分是 model_fn\n",
    "    \n",
    "    def model_fn(features, labels, mode, params, config):\n",
    "        logits = create_model(features, params['feature_columns'], params['hiddens'], params['output_dim'])\n",
    "        predict_pro  = tf.nn.softmax(logits)\n",
    "        predict_cls = tf.argmax(logits, axis=1)\n",
    "        if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "            loss = tf.losses.sparse_softmax_cross_entropy(labels=labels,logits=logits)\n",
    "\n",
    "        def get_metric(labels, predictions):\n",
    "            '''\n",
    "            define metrics\n",
    "            '''\n",
    "            accuracy = tf.metrics.accuracy(labels=labels, \n",
    "                                           predictions=predictions, \n",
    "                                           name='iris_accuracy')\n",
    "            recall = tf.metrics.recall(labels=labels,\n",
    "                                       predictions=predictions,\n",
    "                                       name='iris_recall')\n",
    "            precision, precision_update=tf.metrics.precision(labels=labels,predictions=predictions,name='iris_precision')\n",
    "            \n",
    "            return {\n",
    "                'accuracy':accuracy,\n",
    "                'recall': recall,\n",
    "                'precision':(precision,precision_update)                  \n",
    "            }\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            train_op = tf.train.AdamOptimizer(lr).minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                              loss=loss,\n",
    "                                              train_op=train_op,\n",
    "                                              eval_metric_ops=get_metric(labels,predict_cls))\n",
    "        \n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                              loss=loss,\n",
    "                                              eval_metric_ops=get_metric(labels,predict_cls))\n",
    "        \n",
    "        elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            predictions={'predict_cls':predict_cls,\n",
    "                         'predict_pro':predict_pro}\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                              predictions=predictions)  \n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义输入层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出层是一个函数，返回 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_TYPES=[[0.0], [0.0], [0.0], [0.0], [0]]\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'label']\n",
    "label = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "def input_fn_builder(file_path, epochs, batch_size, istrain=False):\n",
    "    \n",
    "    def parse_line(line): # 这个给 map 函数用来解析行\n",
    "        '''\n",
    "        parse csv line to features fromat\n",
    "        '''\n",
    "        fileds = tf.decode_csv(line,record_defaults=CSV_TYPES)\n",
    "        features = dict(zip(CSV_COLUMN_NAMES,fileds))\n",
    "        label = features.pop('label')\n",
    "        return features,label\n",
    "    \n",
    "    def input_fn():\n",
    "        dataset = tf.data.TextLineDataset(file_path).skip(1)\n",
    "        dataset = dataset.map(parse_line)\n",
    "        if istrain:\n",
    "            dataset = dataset.shuffle(1000)\n",
    "        dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "        return dataset # 返回的 顺序要和 model_fn一致 或者 dataset元素 格式为（features,label）元组 也可以\n",
    "    \n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = r'./model'\n",
    "params = {}\n",
    "feature_columns = []\n",
    "for i in range(len(CSV_COLUMN_NAMES)-1):\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(CSV_COLUMN_NAMES[i])\n",
    "    )\n",
    "params['feature_columns'] = feature_columns\n",
    "params['hiddens'] = [128, 256, 256]\n",
    "params['output_dim'] = len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8bf1040510>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "config = tf.estimator.RunConfig(save_checkpoints_steps=100)\n",
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn_builder(LR), # 这里需要一个函数\n",
    "    model_dir=model_dir, \n",
    "    params=params,\n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column.py:206: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column.py:2158: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column.py:207: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-184dad39fb8d>:5: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "train\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2200: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-80\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 80 into ./model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.57556534, step = 81\n",
      "INFO:tensorflow:Saving checkpoints for 120 into ./model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.5781127.\n"
     ]
    }
   ],
   "source": [
    "train = estimator.train(input_fn=input_fn_builder(file_path=train_path,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    epochs=EPOCHS), # 这里也需要一个函数\n",
    "                        steps=STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "eval\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-02-03T15:55:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [4/40]\n",
      "INFO:tensorflow:Evaluation [8/40]\n",
      "INFO:tensorflow:Evaluation [12/40]\n",
      "INFO:tensorflow:Evaluation [16/40]\n",
      "INFO:tensorflow:Evaluation [20/40]\n",
      "INFO:tensorflow:Evaluation [24/40]\n",
      "INFO:tensorflow:Evaluation [28/40]\n",
      "INFO:tensorflow:Evaluation [32/40]\n",
      "INFO:tensorflow:Evaluation [36/40]\n",
      "INFO:tensorflow:Evaluation [40/40]\n",
      "INFO:tensorflow:Finished evaluation at 2021-02-03-15:55:23\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.7859375, global_step = 120, loss = 0.48074174, precision = 1.0, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: ./model/model.ckpt-120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7859375,\n",
       " 'loss': 0.48074174,\n",
       " 'precision': 1.0,\n",
       " 'recall': 1.0,\n",
       " 'global_step': 120}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate(  input_fn,    steps=None,    hooks=None,    checkpoint_path=None,    name=None)\n",
    "estimator.evaluate(input_fn=input_fn_builder(file_path=test_path,\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            epochs=EPOCHS), steps=STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x7f8bf102ea50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict(    input_fn,    predict_keys=None,    hooks=None,    checkpoint_path=None,    yield_single_examples=True)\n",
    "estimator.predict(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow 使用 pb 模型格式作为 serving 的模型。而 train 和 test 还都是 checkpoint 格式的数据，需要将我们 train 出来的 checkpoint 格式的数据转换为 pb 格式的数据。\n",
    "\n",
    "`tf.estimator` 提供了 `tf.estimator.export_savedmodel` 这个函数来实现上面的功能，它做了下面的几件事\n",
    "\n",
    "1. 增加placeholders到graph中，serving系统在获得inference请求时会进行feed数据\n",
    "\n",
    "2. 增加了额外ops：可以将原有输入格式的数据转换成模型所需特征tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 serving 层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.estimator.export.ServingInputReceiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    input_str = tf.placeholder(tf.string,name='inputs')\n",
    "    \n",
    "    # 在这里的处理方式，根据输入的不同，处理方式 会不同，我这里只是demo\n",
    "    line = tf.string_split(input_str,',').values \n",
    "    features = {\n",
    "      'SepalLength': tf.string_to_number([line[0]], tf.float32),\n",
    "      'SepalWidth': tf.string_to_number([line[1]], tf.float32),\n",
    "      'PetalLength':  tf.string_to_number([line[2]], tf.float32),\n",
    "      'PetalWidth': tf.string_to_number([line[3]], tf.float32)\n",
    "    }   \n",
    "    \n",
    "    receiver_tensors = {'inputs': input_str}\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的例子中，有 receiver_tensors 和 features，其中 reciever_tensors 是我们的输入，而 reciever_tensors 是模型的输入。 `serving_input_receiver_fn` 的第二个作用就是编写将 receiver_tensors 变成 features 的逻辑。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.estimator.export.build_raw_serving_input_receiver_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们的输入不需要经过处理，那么可以简单的使用 `tf.estimator.export.build_raw_serving_input_receiver_fn` 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_serving_input_fn():\n",
    "    SepalLength = tf.placeholder(tf.float32, [None], name='SepalLength')\n",
    "    SepalWidth = tf.placeholder(tf.float32, [None], name='SepalWidth')\n",
    "    PetalLength = tf.placeholder(tf.float32, [None], name='PetalLength')\n",
    "    PetalWidth = tf.placeholder(tf.float32, [None], name='PetalWidth')\n",
    "    input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
    "        'SepalLength': SepalLength,\n",
    "        'SepalWidth': SepalWidth,\n",
    "        'PetalLength': PetalLength,\n",
    "        'PetalWidth': PetalWidth,\n",
    "    })()\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-91679563a4f1>:1: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function has been renamed, use `export_saved_model` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "infer\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-120\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: export_base/iris/temp-b'1612338923'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'export_base/iris/1612338923'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.export_savedmodel('export_base/iris', serving_input_receiver_fn=raw_serving_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，export_base/iris 目录下多了一个 1611673453 目录，这个目录中存放这 pb 文件和 variables 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mexport_base/iris\u001b[00m\r\n",
      "├── \u001b[01;34m1611673453\u001b[00m\r\n",
      "│   ├── saved_model.pb\r\n",
      "│   └── \u001b[01;34mvariables\u001b[00m\r\n",
      "│       ├── variables.data-00000-of-00001\r\n",
      "│       └── variables.index\r\n",
      "└── \u001b[01;34m1612338923\u001b[00m\r\n",
      "    ├── saved_model.pb\r\n",
      "    └── \u001b[01;34mvariables\u001b[00m\r\n",
      "        ├── variables.data-00000-of-00001\r\n",
      "        └── variables.index\r\n",
      "\r\n",
      "4 directories, 6 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree export_base/iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 saved_model_cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['PetalLength'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1)\r\n",
      "        name: PetalLength_1:0\r\n",
      "    inputs['PetalWidth'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1)\r\n",
      "        name: PetalWidth_1:0\r\n",
      "    inputs['SepalLength'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1)\r\n",
      "        name: SepalLength_1:0\r\n",
      "    inputs['SepalWidth'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1)\r\n",
      "        name: SepalWidth_1:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['predict_cls'] tensor_info:\r\n",
      "        dtype: DT_INT64\r\n",
      "        shape: (-1)\r\n",
      "        name: ArgMax:0\r\n",
      "    outputs['predict_pro'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 3)\r\n",
      "        name: Softmax:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir export_base/iris/1611673453 --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 saved_model_cli 还可以用一组输入进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-03 15:55:27.571696: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2021-02-03 15:55:27.584064: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f98f6138b40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-03 15:55:27.584112: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tars/lib/python3.7/site-packages/tensorflow_core/python/tools/saved_model_cli.py:420: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "Result for output key predict_cls:\n",
      "[0 2 2]\n",
      "Result for output key predict_pro:\n",
      "[[0.66284543 0.18443526 0.15271927]\n",
      " [0.17048366 0.37887084 0.45064554]\n",
      " [0.08769966 0.36253315 0.54976714]]\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli run --dir export_base/iris/1611673453 \\\n",
    "    --tag_set serve \\\n",
    "    --signature_def \"serving_default\" \\\n",
    "    --input_expr 'SepalLength=[5.1,5.9,6.9];SepalWidth=[3.3,3.0,3.1];PetalLength=[1.7,4.2,5.4];PetalWidth=[0.5,1.5,2.1]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-febe8a50858e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-febe8a50858e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    saved_model_cli run --dir intent_model_correct-1.savedmodel/1611676053 \\\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "saved_model_cli run --dir slot_model.savedmodel/1612339274 \\\n",
    "    --tag_set serve \\\n",
    "    --signature_def \"serving_default\" \\\n",
    "    --input_expr 'input_ids=[[1,2,3,4,5,6,7,8,9,10]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'export_base/iris/1608121703'\n",
    "# 2. 使用 tornado/flask\n",
    "# steps：\n",
    "# 1. load model\n",
    "predictor = tf.contrib.predictor.from_saved_model(model_path) # model_path必须指定具体的版本号\n",
    "\n",
    "# 2. predict\n",
    "predict_result = predictor(input_params) # input_params 格式必须 符合 serving_input_receiver_fn中入参\n",
    "                                        #     predict_result 格式和 model_fn中返回格式一致\n",
    "# 3. using tornado\n",
    "class b_vxHandler(tornado.web.RequestHandler): \n",
    "\n",
    "    def post(self, version):\n",
    "        try:\n",
    "            predict_result = predictor(input_params)\n",
    "        except BaseException as err:\n",
    "            self.finish(....)\n",
    "\n",
    "\n",
    "application = tornado.web.Application([\n",
    "    (r\"/b/(?P<version>v\\d+)\", b_vxHandler),\n",
    "])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # tornado.options.parse_command_line()\n",
    "    application.listen(options.port)\n",
    "    tornado.ioloop.IOLoop.instance().start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. [《Estimator工程实现》系列三： SavedModel模型保存导出示例 - 简书](https://www.jianshu.com/p/72058da4d7f7)\n",
    "\n",
    "2. [tensorflow中模型的保存与使用总结 — carlos9310](https://carlos9310.github.io/2019/10/13/tensorflow-model-save-use/#run)\n",
    "\n",
    "3. [TensorFlow之estimator详解 - marsggbo - 博客园](https://www.cnblogs.com/marsggbo/p/11232897.html#%E4%BB%80%E4%B9%88%E6%98%AFtf.estimator.estimatorspec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tars]",
   "language": "python",
   "name": "conda-env-tars-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
